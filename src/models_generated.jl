# This file is auto-generated from models.generated.ts
# Do not edit manually

# Initialize model registry
function _init_model_registry!()
    empty!(_model_registry)
    
    # anthropic models
    _model_registry["anthropic"] = Dict{String,Model}(
        "claude-opus-4-0" => Model(
            id="claude-opus-4-0",
            name="Claude Opus 4 (latest)",
            api="anthropic-messages",
            provider="anthropic",
            baseUrl="https://api.anthropic.com",
            reasoning=true,
            input=["text", "image"],
            cost=Dict("input"=>15, "output"=>75, "cacheRead"=>1.5, "cacheWrite"=>18.75),
            contextWindow=200000,
            maxTokens=32000,
            headers=nothing
        ),
        "claude-3-5-sonnet-20241022" => Model(
            id="claude-3-5-sonnet-20241022",
            name="Claude Sonnet 3.5 v2",
            api="anthropic-messages",
            provider="anthropic",
            baseUrl="https://api.anthropic.com",
            reasoning=false,
            input=["text", "image"],
            cost=Dict("input"=>3, "output"=>15, "cacheRead"=>0.3, "cacheWrite"=>3.75),
            contextWindow=200000,
            maxTokens=8192,
            headers=nothing
        ),
        "claude-opus-4-1" => Model(
            id="claude-opus-4-1",
            name="Claude Opus 4.1 (latest)",
            api="anthropic-messages",
            provider="anthropic",
            baseUrl="https://api.anthropic.com",
            reasoning=true,
            input=["text", "image"],
            cost=Dict("input"=>15, "output"=>75, "cacheRead"=>1.5, "cacheWrite"=>18.75),
            contextWindow=200000,
            maxTokens=32000,
            headers=nothing
        ),
        "claude-haiku-4-5" => Model(
            id="claude-haiku-4-5",
            name="Claude Haiku 4.5 (latest)",
            api="anthropic-messages",
            provider="anthropic",
            baseUrl="https://api.anthropic.com",
            reasoning=true,
            input=["text", "image"],
            cost=Dict("input"=>1, "output"=>5, "cacheRead"=>0.1, "cacheWrite"=>1.25),
            contextWindow=200000,
            maxTokens=64000,
            headers=nothing
        ),
        "claude-3-5-sonnet-20240620" => Model(
            id="claude-3-5-sonnet-20240620",
            name="Claude Sonnet 3.5",
            api="anthropic-messages",
            provider="anthropic",
            baseUrl="https://api.anthropic.com",
            reasoning=false,
            input=["text", "image"],
            cost=Dict("input"=>3, "output"=>15, "cacheRead"=>0.3, "cacheWrite"=>3.75),
            contextWindow=200000,
            maxTokens=8192,
            headers=nothing
        ),
        "claude-3-5-haiku-latest" => Model(
            id="claude-3-5-haiku-latest",
            name="Claude Haiku 3.5 (latest)",
            api="anthropic-messages",
            provider="anthropic",
            baseUrl="https://api.anthropic.com",
            reasoning=false,
            input=["text", "image"],
            cost=Dict("input"=>0.8, "output"=>4, "cacheRead"=>0.08, "cacheWrite"=>1),
            contextWindow=200000,
            maxTokens=8192,
            headers=nothing
        ),
        "claude-opus-4-5" => Model(
            id="claude-opus-4-5",
            name="Claude Opus 4.5 (latest)",
            api="anthropic-messages",
            provider="anthropic",
            baseUrl="https://api.anthropic.com",
            reasoning=true,
            input=["text", "image"],
            cost=Dict("input"=>5, "output"=>25, "cacheRead"=>0.5, "cacheWrite"=>6.25),
            contextWindow=200000,
            maxTokens=64000,
            headers=nothing
        ),
        "claude-3-opus-20240229" => Model(
            id="claude-3-opus-20240229",
            name="Claude Opus 3",
            api="anthropic-messages",
            provider="anthropic",
            baseUrl="https://api.anthropic.com",
            reasoning=false,
            input=["text", "image"],
            cost=Dict("input"=>15, "output"=>75, "cacheRead"=>1.5, "cacheWrite"=>18.75),
            contextWindow=200000,
            maxTokens=4096,
            headers=nothing
        ),
        "claude-opus-4-5-20251101" => Model(
            id="claude-opus-4-5-20251101",
            name="Claude Opus 4.5",
            api="anthropic-messages",
            provider="anthropic",
            baseUrl="https://api.anthropic.com",
            reasoning=true,
            input=["text", "image"],
            cost=Dict("input"=>5, "output"=>25, "cacheRead"=>0.5, "cacheWrite"=>6.25),
            contextWindow=200000,
            maxTokens=64000,
            headers=nothing
        ),
        "claude-sonnet-4-5" => Model(
            id="claude-sonnet-4-5",
            name="Claude Sonnet 4.5 (latest)",
            api="anthropic-messages",
            provider="anthropic",
            baseUrl="https://api.anthropic.com",
            reasoning=true,
            input=["text", "image"],
            cost=Dict("input"=>3, "output"=>15, "cacheRead"=>0.3, "cacheWrite"=>3.75),
            contextWindow=200000,
            maxTokens=64000,
            headers=nothing
        ),
        "claude-sonnet-4-5-20250929" => Model(
            id="claude-sonnet-4-5-20250929",
            name="Claude Sonnet 4.5",
            api="anthropic-messages",
            provider="anthropic",
            baseUrl="https://api.anthropic.com",
            reasoning=true,
            input=["text", "image"],
            cost=Dict("input"=>3, "output"=>15, "cacheRead"=>0.3, "cacheWrite"=>3.75),
            contextWindow=200000,
            maxTokens=64000,
            headers=nothing
        ),
        "claude-sonnet-4-20250514" => Model(
            id="claude-sonnet-4-20250514",
            name="Claude Sonnet 4",
            api="anthropic-messages",
            provider="anthropic",
            baseUrl="https://api.anthropic.com",
            reasoning=true,
            input=["text", "image"],
            cost=Dict("input"=>3, "output"=>15, "cacheRead"=>0.3, "cacheWrite"=>3.75),
            contextWindow=200000,
            maxTokens=64000,
            headers=nothing
        ),
        "claude-opus-4-20250514" => Model(
            id="claude-opus-4-20250514",
            name="Claude Opus 4",
            api="anthropic-messages",
            provider="anthropic",
            baseUrl="https://api.anthropic.com",
            reasoning=true,
            input=["text", "image"],
            cost=Dict("input"=>15, "output"=>75, "cacheRead"=>1.5, "cacheWrite"=>18.75),
            contextWindow=200000,
            maxTokens=32000,
            headers=nothing
        ),
        "claude-3-5-haiku-20241022" => Model(
            id="claude-3-5-haiku-20241022",
            name="Claude Haiku 3.5",
            api="anthropic-messages",
            provider="anthropic",
            baseUrl="https://api.anthropic.com",
            reasoning=false,
            input=["text", "image"],
            cost=Dict("input"=>0.8, "output"=>4, "cacheRead"=>0.08, "cacheWrite"=>1),
            contextWindow=200000,
            maxTokens=8192,
            headers=nothing
        ),
        "claude-3-haiku-20240307" => Model(
            id="claude-3-haiku-20240307",
            name="Claude Haiku 3",
            api="anthropic-messages",
            provider="anthropic",
            baseUrl="https://api.anthropic.com",
            reasoning=false,
            input=["text", "image"],
            cost=Dict("input"=>0.25, "output"=>1.25, "cacheRead"=>0.03, "cacheWrite"=>0.3),
            contextWindow=200000,
            maxTokens=4096,
            headers=nothing
        ),
        "claude-3-7-sonnet-20250219" => Model(
            id="claude-3-7-sonnet-20250219",
            name="Claude Sonnet 3.7",
            api="anthropic-messages",
            provider="anthropic",
            baseUrl="https://api.anthropic.com",
            reasoning=true,
            input=["text", "image"],
            cost=Dict("input"=>3, "output"=>15, "cacheRead"=>0.3, "cacheWrite"=>3.75),
            contextWindow=200000,
            maxTokens=64000,
            headers=nothing
        ),
        "claude-3-7-sonnet-latest" => Model(
            id="claude-3-7-sonnet-latest",
            name="Claude Sonnet 3.7 (latest)",
            api="anthropic-messages",
            provider="anthropic",
            baseUrl="https://api.anthropic.com",
            reasoning=true,
            input=["text", "image"],
            cost=Dict("input"=>3, "output"=>15, "cacheRead"=>0.3, "cacheWrite"=>3.75),
            contextWindow=200000,
            maxTokens=64000,
            headers=nothing
        ),
        "claude-sonnet-4-0" => Model(
            id="claude-sonnet-4-0",
            name="Claude Sonnet 4 (latest)",
            api="anthropic-messages",
            provider="anthropic",
            baseUrl="https://api.anthropic.com",
            reasoning=true,
            input=["text", "image"],
            cost=Dict("input"=>3, "output"=>15, "cacheRead"=>0.3, "cacheWrite"=>3.75),
            contextWindow=200000,
            maxTokens=64000,
            headers=nothing
        ),
        "claude-opus-4-1-20250805" => Model(
            id="claude-opus-4-1-20250805",
            name="Claude Opus 4.1",
            api="anthropic-messages",
            provider="anthropic",
            baseUrl="https://api.anthropic.com",
            reasoning=true,
            input=["text", "image"],
            cost=Dict("input"=>15, "output"=>75, "cacheRead"=>1.5, "cacheWrite"=>18.75),
            contextWindow=200000,
            maxTokens=32000,
            headers=nothing
        ),
        "claude-3-sonnet-20240229" => Model(
            id="claude-3-sonnet-20240229",
            name="Claude Sonnet 3",
            api="anthropic-messages",
            provider="anthropic",
            baseUrl="https://api.anthropic.com",
            reasoning=false,
            input=["text", "image"],
            cost=Dict("input"=>3, "output"=>15, "cacheRead"=>0.3, "cacheWrite"=>0.3),
            contextWindow=200000,
            maxTokens=4096,
            headers=nothing
        ),
        "claude-haiku-4-5-20251001" => Model(
            id="claude-haiku-4-5-20251001",
            name="Claude Haiku 4.5",
            api="anthropic-messages",
            provider="anthropic",
            baseUrl="https://api.anthropic.com",
            reasoning=true,
            input=["text", "image"],
            cost=Dict("input"=>1, "output"=>5, "cacheRead"=>0.1, "cacheWrite"=>1.25),
            contextWindow=200000,
            maxTokens=64000,
            headers=nothing
        ),
    )

    # google models
    _model_registry["google"] = Dict{String,Model}(
        "gemini-2.5-flash-preview-05-20" => Model(
            id="gemini-2.5-flash-preview-05-20",
            name="Gemini 2.5 Flash Preview 05-20",
            api="google-generative-ai",
            provider="google",
            baseUrl="https://generativelanguage.googleapis.com/v1beta",
            reasoning=true,
            input=["text", "image"],
            cost=Dict("input"=>0.15, "output"=>0.6, "cacheRead"=>0.0375, "cacheWrite"=>0),
            contextWindow=1048576,
            maxTokens=65536,
            headers=nothing
        ),
        "gemini-flash-lite-latest" => Model(
            id="gemini-flash-lite-latest",
            name="Gemini Flash-Lite Latest",
            api="google-generative-ai",
            provider="google",
            baseUrl="https://generativelanguage.googleapis.com/v1beta",
            reasoning=true,
            input=["text", "image"],
            cost=Dict("input"=>0.1, "output"=>0.4, "cacheRead"=>0.025, "cacheWrite"=>0),
            contextWindow=1048576,
            maxTokens=65536,
            headers=nothing
        ),
        "gemini-3-pro-preview" => Model(
            id="gemini-3-pro-preview",
            name="Gemini 3 Pro Preview",
            api="google-generative-ai",
            provider="google",
            baseUrl="https://generativelanguage.googleapis.com/v1beta",
            reasoning=true,
            input=["text", "image"],
            cost=Dict("input"=>2, "output"=>12, "cacheRead"=>0.2, "cacheWrite"=>0),
            contextWindow=1000000,
            maxTokens=64000,
            headers=nothing
        ),
        "gemini-2.5-flash" => Model(
            id="gemini-2.5-flash",
            name="Gemini 2.5 Flash",
            api="google-generative-ai",
            provider="google",
            baseUrl="https://generativelanguage.googleapis.com/v1beta",
            reasoning=true,
            input=["text", "image"],
            cost=Dict("input"=>0.3, "output"=>2.5, "cacheRead"=>0.075, "cacheWrite"=>0),
            contextWindow=1048576,
            maxTokens=65536,
            headers=nothing
        ),
        "gemini-flash-latest" => Model(
            id="gemini-flash-latest",
            name="Gemini Flash Latest",
            api="google-generative-ai",
            provider="google",
            baseUrl="https://generativelanguage.googleapis.com/v1beta",
            reasoning=true,
            input=["text", "image"],
            cost=Dict("input"=>0.3, "output"=>2.5, "cacheRead"=>0.075, "cacheWrite"=>0),
            contextWindow=1048576,
            maxTokens=65536,
            headers=nothing
        ),
        "gemini-2.5-pro-preview-05-06" => Model(
            id="gemini-2.5-pro-preview-05-06",
            name="Gemini 2.5 Pro Preview 05-06",
            api="google-generative-ai",
            provider="google",
            baseUrl="https://generativelanguage.googleapis.com/v1beta",
            reasoning=true,
            input=["text", "image"],
            cost=Dict("input"=>1.25, "output"=>10, "cacheRead"=>0.31, "cacheWrite"=>0),
            contextWindow=1048576,
            maxTokens=65536,
            headers=nothing
        ),
        "gemini-2.0-flash-lite" => Model(
            id="gemini-2.0-flash-lite",
            name="Gemini 2.0 Flash Lite",
            api="google-generative-ai",
            provider="google",
            baseUrl="https://generativelanguage.googleapis.com/v1beta",
            reasoning=false,
            input=["text", "image"],
            cost=Dict("input"=>0.075, "output"=>0.3, "cacheRead"=>0, "cacheWrite"=>0),
            contextWindow=1048576,
            maxTokens=8192,
            headers=nothing
        ),
        "gemini-live-2.5-flash-preview-native-audio" => Model(
            id="gemini-live-2.5-flash-preview-native-audio",
            name="Gemini Live 2.5 Flash Preview Native Audio",
            api="google-generative-ai",
            provider="google",
            baseUrl="https://generativelanguage.googleapis.com/v1beta",
            reasoning=true,
            input=["text"],
            cost=Dict("input"=>0.5, "output"=>2, "cacheRead"=>0, "cacheWrite"=>0),
            contextWindow=131072,
            maxTokens=65536,
            headers=nothing
        ),
        "gemini-2.0-flash" => Model(
            id="gemini-2.0-flash",
            name="Gemini 2.0 Flash",
            api="google-generative-ai",
            provider="google",
            baseUrl="https://generativelanguage.googleapis.com/v1beta",
            reasoning=false,
            input=["text", "image"],
            cost=Dict("input"=>0.1, "output"=>0.4, "cacheRead"=>0.025, "cacheWrite"=>0),
            contextWindow=1048576,
            maxTokens=8192,
            headers=nothing
        ),
        "gemini-2.5-flash-lite" => Model(
            id="gemini-2.5-flash-lite",
            name="Gemini 2.5 Flash Lite",
            api="google-generative-ai",
            provider="google",
            baseUrl="https://generativelanguage.googleapis.com/v1beta",
            reasoning=true,
            input=["text", "image"],
            cost=Dict("input"=>0.1, "output"=>0.4, "cacheRead"=>0.025, "cacheWrite"=>0),
            contextWindow=1048576,
            maxTokens=65536,
            headers=nothing
        ),
        "gemini-2.5-pro-preview-06-05" => Model(
            id="gemini-2.5-pro-preview-06-05",
            name="Gemini 2.5 Pro Preview 06-05",
            api="google-generative-ai",
            provider="google",
            baseUrl="https://generativelanguage.googleapis.com/v1beta",
            reasoning=true,
            input=["text", "image"],
            cost=Dict("input"=>1.25, "output"=>10, "cacheRead"=>0.31, "cacheWrite"=>0),
            contextWindow=1048576,
            maxTokens=65536,
            headers=nothing
        ),
        "gemini-live-2.5-flash" => Model(
            id="gemini-live-2.5-flash",
            name="Gemini Live 2.5 Flash",
            api="google-generative-ai",
            provider="google",
            baseUrl="https://generativelanguage.googleapis.com/v1beta",
            reasoning=true,
            input=["text", "image"],
            cost=Dict("input"=>0.5, "output"=>2, "cacheRead"=>0, "cacheWrite"=>0),
            contextWindow=128000,
            maxTokens=8000,
            headers=nothing
        ),
        "gemini-2.5-flash-lite-preview-06-17" => Model(
            id="gemini-2.5-flash-lite-preview-06-17",
            name="Gemini 2.5 Flash Lite Preview 06-17",
            api="google-generative-ai",
            provider="google",
            baseUrl="https://generativelanguage.googleapis.com/v1beta",
            reasoning=true,
            input=["text", "image"],
            cost=Dict("input"=>0.1, "output"=>0.4, "cacheRead"=>0.025, "cacheWrite"=>0),
            contextWindow=1048576,
            maxTokens=65536,
            headers=nothing
        ),
        "gemini-2.5-flash-preview-09-2025" => Model(
            id="gemini-2.5-flash-preview-09-2025",
            name="Gemini 2.5 Flash Preview 09-25",
            api="google-generative-ai",
            provider="google",
            baseUrl="https://generativelanguage.googleapis.com/v1beta",
            reasoning=true,
            input=["text", "image"],
            cost=Dict("input"=>0.3, "output"=>2.5, "cacheRead"=>0.075, "cacheWrite"=>0),
            contextWindow=1048576,
            maxTokens=65536,
            headers=nothing
        ),
        "gemini-2.5-flash-preview-04-17" => Model(
            id="gemini-2.5-flash-preview-04-17",
            name="Gemini 2.5 Flash Preview 04-17",
            api="google-generative-ai",
            provider="google",
            baseUrl="https://generativelanguage.googleapis.com/v1beta",
            reasoning=true,
            input=["text", "image"],
            cost=Dict("input"=>0.15, "output"=>0.6, "cacheRead"=>0.0375, "cacheWrite"=>0),
            contextWindow=1048576,
            maxTokens=65536,
            headers=nothing
        ),
        "gemini-2.5-pro" => Model(
            id="gemini-2.5-pro",
            name="Gemini 2.5 Pro",
            api="google-generative-ai",
            provider="google",
            baseUrl="https://generativelanguage.googleapis.com/v1beta",
            reasoning=true,
            input=["text", "image"],
            cost=Dict("input"=>1.25, "output"=>10, "cacheRead"=>0.31, "cacheWrite"=>0),
            contextWindow=1048576,
            maxTokens=65536,
            headers=nothing
        ),
        "gemini-1.5-flash" => Model(
            id="gemini-1.5-flash",
            name="Gemini 1.5 Flash",
            api="google-generative-ai",
            provider="google",
            baseUrl="https://generativelanguage.googleapis.com/v1beta",
            reasoning=false,
            input=["text", "image"],
            cost=Dict("input"=>0.075, "output"=>0.3, "cacheRead"=>0.01875, "cacheWrite"=>0),
            contextWindow=1000000,
            maxTokens=8192,
            headers=nothing
        ),
        "gemini-1.5-flash-8b" => Model(
            id="gemini-1.5-flash-8b",
            name="Gemini 1.5 Flash-8B",
            api="google-generative-ai",
            provider="google",
            baseUrl="https://generativelanguage.googleapis.com/v1beta",
            reasoning=false,
            input=["text", "image"],
            cost=Dict("input"=>0.0375, "output"=>0.15, "cacheRead"=>0.01, "cacheWrite"=>0),
            contextWindow=1000000,
            maxTokens=8192,
            headers=nothing
        ),
        "gemini-2.5-flash-lite-preview-09-2025" => Model(
            id="gemini-2.5-flash-lite-preview-09-2025",
            name="Gemini 2.5 Flash Lite Preview 09-25",
            api="google-generative-ai",
            provider="google",
            baseUrl="https://generativelanguage.googleapis.com/v1beta",
            reasoning=true,
            input=["text", "image"],
            cost=Dict("input"=>0.1, "output"=>0.4, "cacheRead"=>0.025, "cacheWrite"=>0),
            contextWindow=1048576,
            maxTokens=65536,
            headers=nothing
        ),
        "gemini-1.5-pro" => Model(
            id="gemini-1.5-pro",
            name="Gemini 1.5 Pro",
            api="google-generative-ai",
            provider="google",
            baseUrl="https://generativelanguage.googleapis.com/v1beta",
            reasoning=false,
            input=["text", "image"],
            cost=Dict("input"=>1.25, "output"=>5, "cacheRead"=>0.3125, "cacheWrite"=>0),
            contextWindow=1000000,
            maxTokens=8192,
            headers=nothing
        ),
    )

    # openai models
    _model_registry["openai"] = Dict{String,Model}(
        "gpt-4.1-nano" => Model(
            id="gpt-4.1-nano",
            name="GPT-4.1 nano",
            api="openai-responses",
            provider="openai",
            baseUrl="https://api.openai.com/v1",
            reasoning=false,
            input=["text", "image"],
            cost=Dict("input"=>0.1, "output"=>0.4, "cacheRead"=>0.03, "cacheWrite"=>0),
            contextWindow=1047576,
            maxTokens=32768,
            headers=nothing
        ),
        "gpt-4" => Model(
            id="gpt-4",
            name="GPT-4",
            api="openai-responses",
            provider="openai",
            baseUrl="https://api.openai.com/v1",
            reasoning=false,
            input=["text"],
            cost=Dict("input"=>30, "output"=>60, "cacheRead"=>0, "cacheWrite"=>0),
            contextWindow=8192,
            maxTokens=8192,
            headers=nothing
        ),
        "o1-pro" => Model(
            id="o1-pro",
            name="o1-pro",
            api="openai-responses",
            provider="openai",
            baseUrl="https://api.openai.com/v1",
            reasoning=true,
            input=["text", "image"],
            cost=Dict("input"=>150, "output"=>600, "cacheRead"=>0, "cacheWrite"=>0),
            contextWindow=200000,
            maxTokens=100000,
            headers=nothing
        ),
        "gpt-4o-2024-05-13" => Model(
            id="gpt-4o-2024-05-13",
            name="GPT-4o (2024-05-13)",
            api="openai-responses",
            provider="openai",
            baseUrl="https://api.openai.com/v1",
            reasoning=false,
            input=["text", "image"],
            cost=Dict("input"=>5, "output"=>15, "cacheRead"=>0, "cacheWrite"=>0),
            contextWindow=128000,
            maxTokens=4096,
            headers=nothing
        ),
        "gpt-5.1-codex" => Model(
            id="gpt-5.1-codex",
            name="GPT-5.1 Codex",
            api="openai-responses",
            provider="openai",
            baseUrl="https://api.openai.com/v1",
            reasoning=true,
            input=["text", "image"],
            cost=Dict("input"=>1.25, "output"=>10, "cacheRead"=>0.125, "cacheWrite"=>0),
            contextWindow=400000,
            maxTokens=128000,
            headers=nothing
        ),
        "gpt-4o-2024-08-06" => Model(
            id="gpt-4o-2024-08-06",
            name="GPT-4o (2024-08-06)",
            api="openai-responses",
            provider="openai",
            baseUrl="https://api.openai.com/v1",
            reasoning=false,
            input=["text", "image"],
            cost=Dict("input"=>2.5, "output"=>10, "cacheRead"=>1.25, "cacheWrite"=>0),
            contextWindow=128000,
            maxTokens=16384,
            headers=nothing
        ),
        "gpt-4.1-mini" => Model(
            id="gpt-4.1-mini",
            name="GPT-4.1 mini",
            api="openai-responses",
            provider="openai",
            baseUrl="https://api.openai.com/v1",
            reasoning=false,
            input=["text", "image"],
            cost=Dict("input"=>0.4, "output"=>1.6, "cacheRead"=>0.1, "cacheWrite"=>0),
            contextWindow=1047576,
            maxTokens=32768,
            headers=nothing
        ),
        "o3-deep-research" => Model(
            id="o3-deep-research",
            name="o3-deep-research",
            api="openai-responses",
            provider="openai",
            baseUrl="https://api.openai.com/v1",
            reasoning=true,
            input=["text", "image"],
            cost=Dict("input"=>10, "output"=>40, "cacheRead"=>2.5, "cacheWrite"=>0),
            contextWindow=200000,
            maxTokens=100000,
            headers=nothing
        ),
        "gpt-4-turbo" => Model(
            id="gpt-4-turbo",
            name="GPT-4 Turbo",
            api="openai-responses",
            provider="openai",
            baseUrl="https://api.openai.com/v1",
            reasoning=false,
            input=["text", "image"],
            cost=Dict("input"=>10, "output"=>30, "cacheRead"=>0, "cacheWrite"=>0),
            contextWindow=128000,
            maxTokens=4096,
            headers=nothing
        ),
        "gpt-5.1-codex-mini" => Model(
            id="gpt-5.1-codex-mini",
            name="GPT-5.1 Codex mini",
            api="openai-responses",
            provider="openai",
            baseUrl="https://api.openai.com/v1",
            reasoning=true,
            input=["text", "image"],
            cost=Dict("input"=>0.25, "output"=>2, "cacheRead"=>0.025, "cacheWrite"=>0),
            contextWindow=400000,
            maxTokens=128000,
            headers=nothing
        ),
        "o3-mini" => Model(
            id="o3-mini",
            name="o3-mini",
            api="openai-responses",
            provider="openai",
            baseUrl="https://api.openai.com/v1",
            reasoning=true,
            input=["text"],
            cost=Dict("input"=>1.1, "output"=>4.4, "cacheRead"=>0.55, "cacheWrite"=>0),
            contextWindow=200000,
            maxTokens=100000,
            headers=nothing
        ),
        "gpt-5.1" => Model(
            id="gpt-5.1",
            name="GPT-5.1",
            api="openai-responses",
            provider="openai",
            baseUrl="https://api.openai.com/v1",
            reasoning=true,
            input=["text", "image"],
            cost=Dict("input"=>1.25, "output"=>10, "cacheRead"=>0.13, "cacheWrite"=>0),
            contextWindow=400000,
            maxTokens=128000,
            headers=nothing
        ),
        "codex-mini-latest" => Model(
            id="codex-mini-latest",
            name="Codex Mini",
            api="openai-responses",
            provider="openai",
            baseUrl="https://api.openai.com/v1",
            reasoning=true,
            input=["text"],
            cost=Dict("input"=>1.5, "output"=>6, "cacheRead"=>0.375, "cacheWrite"=>0),
            contextWindow=200000,
            maxTokens=100000,
            headers=nothing
        ),
        "gpt-5-nano" => Model(
            id="gpt-5-nano",
            name="GPT-5 Nano",
            api="openai-responses",
            provider="openai",
            baseUrl="https://api.openai.com/v1",
            reasoning=true,
            input=["text", "image"],
            cost=Dict("input"=>0.05, "output"=>0.4, "cacheRead"=>0.01, "cacheWrite"=>0),
            contextWindow=400000,
            maxTokens=128000,
            headers=nothing
        ),
        "gpt-5-codex" => Model(
            id="gpt-5-codex",
            name="GPT-5-Codex",
            api="openai-responses",
            provider="openai",
            baseUrl="https://api.openai.com/v1",
            reasoning=true,
            input=["text", "image"],
            cost=Dict("input"=>1.25, "output"=>10, "cacheRead"=>0.125, "cacheWrite"=>0),
            contextWindow=400000,
            maxTokens=128000,
            headers=nothing
        ),
        "gpt-4o" => Model(
            id="gpt-4o",
            name="GPT-4o",
            api="openai-responses",
            provider="openai",
            baseUrl="https://api.openai.com/v1",
            reasoning=false,
            input=["text", "image"],
            cost=Dict("input"=>2.5, "output"=>10, "cacheRead"=>1.25, "cacheWrite"=>0),
            contextWindow=128000,
            maxTokens=16384,
            headers=nothing
        ),
        "gpt-4.1" => Model(
            id="gpt-4.1",
            name="GPT-4.1",
            api="openai-responses",
            provider="openai",
            baseUrl="https://api.openai.com/v1",
            reasoning=false,
            input=["text", "image"],
            cost=Dict("input"=>2, "output"=>8, "cacheRead"=>0.5, "cacheWrite"=>0),
            contextWindow=1047576,
            maxTokens=32768,
            headers=nothing
        ),
        "o4-mini" => Model(
            id="o4-mini",
            name="o4-mini",
            api="openai-responses",
            provider="openai",
            baseUrl="https://api.openai.com/v1",
            reasoning=true,
            input=["text", "image"],
            cost=Dict("input"=>1.1, "output"=>4.4, "cacheRead"=>0.28, "cacheWrite"=>0),
            contextWindow=200000,
            maxTokens=100000,
            headers=nothing
        ),
        "o1" => Model(
            id="o1",
            name="o1",
            api="openai-responses",
            provider="openai",
            baseUrl="https://api.openai.com/v1",
            reasoning=true,
            input=["text", "image"],
            cost=Dict("input"=>15, "output"=>60, "cacheRead"=>7.5, "cacheWrite"=>0),
            contextWindow=200000,
            maxTokens=100000,
            headers=nothing
        ),
        "gpt-5-mini" => Model(
            id="gpt-5-mini",
            name="GPT-5 Mini",
            api="openai-responses",
            provider="openai",
            baseUrl="https://api.openai.com/v1",
            reasoning=true,
            input=["text", "image"],
            cost=Dict("input"=>0.25, "output"=>2, "cacheRead"=>0.03, "cacheWrite"=>0),
            contextWindow=400000,
            maxTokens=128000,
            headers=nothing
        ),
        "o3-pro" => Model(
            id="o3-pro",
            name="o3-pro",
            api="openai-responses",
            provider="openai",
            baseUrl="https://api.openai.com/v1",
            reasoning=true,
            input=["text", "image"],
            cost=Dict("input"=>20, "output"=>80, "cacheRead"=>0, "cacheWrite"=>0),
            contextWindow=200000,
            maxTokens=100000,
            headers=nothing
        ),
        "gpt-4o-2024-11-20" => Model(
            id="gpt-4o-2024-11-20",
            name="GPT-4o (2024-11-20)",
            api="openai-responses",
            provider="openai",
            baseUrl="https://api.openai.com/v1",
            reasoning=false,
            input=["text", "image"],
            cost=Dict("input"=>2.5, "output"=>10, "cacheRead"=>1.25, "cacheWrite"=>0),
            contextWindow=128000,
            maxTokens=16384,
            headers=nothing
        ),
        "o3" => Model(
            id="o3",
            name="o3",
            api="openai-responses",
            provider="openai",
            baseUrl="https://api.openai.com/v1",
            reasoning=true,
            input=["text", "image"],
            cost=Dict("input"=>2, "output"=>8, "cacheRead"=>0.5, "cacheWrite"=>0),
            contextWindow=200000,
            maxTokens=100000,
            headers=nothing
        ),
        "o4-mini-deep-research" => Model(
            id="o4-mini-deep-research",
            name="o4-mini-deep-research",
            api="openai-responses",
            provider="openai",
            baseUrl="https://api.openai.com/v1",
            reasoning=true,
            input=["text", "image"],
            cost=Dict("input"=>2, "output"=>8, "cacheRead"=>0.5, "cacheWrite"=>0),
            contextWindow=200000,
            maxTokens=100000,
            headers=nothing
        ),
        "gpt-4o-mini" => Model(
            id="gpt-4o-mini",
            name="GPT-4o mini",
            api="openai-responses",
            provider="openai",
            baseUrl="https://api.openai.com/v1",
            reasoning=false,
            input=["text", "image"],
            cost=Dict("input"=>0.15, "output"=>0.6, "cacheRead"=>0.08, "cacheWrite"=>0),
            contextWindow=128000,
            maxTokens=16384,
            headers=nothing
        ),
        "gpt-5" => Model(
            id="gpt-5",
            name="GPT-5",
            api="openai-responses",
            provider="openai",
            baseUrl="https://api.openai.com/v1",
            reasoning=true,
            input=["text", "image"],
            cost=Dict("input"=>1.25, "output"=>10, "cacheRead"=>0.13, "cacheWrite"=>0),
            contextWindow=400000,
            maxTokens=128000,
            headers=nothing
        ),
        "gpt-5-pro" => Model(
            id="gpt-5-pro",
            name="GPT-5 Pro",
            api="openai-responses",
            provider="openai",
            baseUrl="https://api.openai.com/v1",
            reasoning=true,
            input=["text", "image"],
            cost=Dict("input"=>15, "output"=>120, "cacheRead"=>0, "cacheWrite"=>0),
            contextWindow=400000,
            maxTokens=272000,
            headers=nothing
        ),
        "gpt-5.1-chat-latest" => Model(
            id="gpt-5.1-chat-latest",
            name="GPT-5.1 Chat",
            api="openai-responses",
            provider="openai",
            baseUrl="https://api.openai.com/v1",
            reasoning=true,
            input=["text", "image"],
            cost=Dict("input"=>1.25, "output"=>10, "cacheRead"=>0.125, "cacheWrite"=>0),
            contextWindow=128000,
            maxTokens=16384,
            headers=nothing
        ),
        "gpt-5-chat-latest" => Model(
            id="gpt-5-chat-latest",
            name="GPT-5 Chat Latest",
            api="openai-responses",
            provider="openai",
            baseUrl="https://api.openai.com/v1",
            reasoning=false,
            input=["text", "image"],
            cost=Dict("input"=>1.25, "output"=>10, "cacheRead"=>0.125, "cacheWrite"=>0),
            contextWindow=128000,
            maxTokens=16384,
            headers=nothing
        ),
    )

    # groq models
    _model_registry["groq"] = Dict{String,Model}(
        "llama-3.1-8b-instant" => Model(
            id="llama-3.1-8b-instant",
            name="Llama 3.1 8B Instant",
            api="openai-completions",
            provider="groq",
            baseUrl="https://api.groq.com/openai/v1",
            reasoning=false,
            input=["text"],
            cost=Dict("input"=>0.05, "output"=>0.08, "cacheRead"=>0, "cacheWrite"=>0),
            contextWindow=131072,
            maxTokens=8192,
            headers=nothing
        ),
        "mistral-saba-24b" => Model(
            id="mistral-saba-24b",
            name="Mistral Saba 24B",
            api="openai-completions",
            provider="groq",
            baseUrl="https://api.groq.com/openai/v1",
            reasoning=false,
            input=["text"],
            cost=Dict("input"=>0.79, "output"=>0.79, "cacheRead"=>0, "cacheWrite"=>0),
            contextWindow=32768,
            maxTokens=32768,
            headers=nothing
        ),
        "llama3-8b-8192" => Model(
            id="llama3-8b-8192",
            name="Llama 3 8B",
            api="openai-completions",
            provider="groq",
            baseUrl="https://api.groq.com/openai/v1",
            reasoning=false,
            input=["text"],
            cost=Dict("input"=>0.05, "output"=>0.08, "cacheRead"=>0, "cacheWrite"=>0),
            contextWindow=8192,
            maxTokens=8192,
            headers=nothing
        ),
        "qwen-qwq-32b" => Model(
            id="qwen-qwq-32b",
            name="Qwen QwQ 32B",
            api="openai-completions",
            provider="groq",
            baseUrl="https://api.groq.com/openai/v1",
            reasoning=true,
            input=["text"],
            cost=Dict("input"=>0.29, "output"=>0.39, "cacheRead"=>0, "cacheWrite"=>0),
            contextWindow=131072,
            maxTokens=16384,
            headers=nothing
        ),
        "llama3-70b-8192" => Model(
            id="llama3-70b-8192",
            name="Llama 3 70B",
            api="openai-completions",
            provider="groq",
            baseUrl="https://api.groq.com/openai/v1",
            reasoning=false,
            input=["text"],
            cost=Dict("input"=>0.59, "output"=>0.79, "cacheRead"=>0, "cacheWrite"=>0),
            contextWindow=8192,
            maxTokens=8192,
            headers=nothing
        ),
        "deepseek-r1-distill-llama-70b" => Model(
            id="deepseek-r1-distill-llama-70b",
            name="DeepSeek R1 Distill Llama 70B",
            api="openai-completions",
            provider="groq",
            baseUrl="https://api.groq.com/openai/v1",
            reasoning=true,
            input=["text"],
            cost=Dict("input"=>0.75, "output"=>0.99, "cacheRead"=>0, "cacheWrite"=>0),
            contextWindow=131072,
            maxTokens=8192,
            headers=nothing
        ),
        "gemma2-9b-it" => Model(
            id="gemma2-9b-it",
            name="Gemma 2 9B",
            api="openai-completions",
            provider="groq",
            baseUrl="https://api.groq.com/openai/v1",
            reasoning=false,
            input=["text"],
            cost=Dict("input"=>0.2, "output"=>0.2, "cacheRead"=>0, "cacheWrite"=>0),
            contextWindow=8192,
            maxTokens=8192,
            headers=nothing
        ),
        "llama-3.3-70b-versatile" => Model(
            id="llama-3.3-70b-versatile",
            name="Llama 3.3 70B Versatile",
            api="openai-completions",
            provider="groq",
            baseUrl="https://api.groq.com/openai/v1",
            reasoning=false,
            input=["text"],
            cost=Dict("input"=>0.59, "output"=>0.79, "cacheRead"=>0, "cacheWrite"=>0),
            contextWindow=131072,
            maxTokens=32768,
            headers=nothing
        ),
        "moonshotai/kimi-k2-instruct-0905" => Model(
            id="moonshotai/kimi-k2-instruct-0905",
            name="Kimi K2 Instruct 0905",
            api="openai-completions",
            provider="groq",
            baseUrl="https://api.groq.com/openai/v1",
            reasoning=false,
            input=["text"],
            cost=Dict("input"=>1, "output"=>3, "cacheRead"=>0, "cacheWrite"=>0),
            contextWindow=262144,
            maxTokens=16384,
            headers=nothing
        ),
        "moonshotai/kimi-k2-instruct" => Model(
            id="moonshotai/kimi-k2-instruct",
            name="Kimi K2 Instruct",
            api="openai-completions",
            provider="groq",
            baseUrl="https://api.groq.com/openai/v1",
            reasoning=false,
            input=["text"],
            cost=Dict("input"=>1, "output"=>3, "cacheRead"=>0, "cacheWrite"=>0),
            contextWindow=131072,
            maxTokens=16384,
            headers=nothing
        ),
        "openai/gpt-oss-20b" => Model(
            id="openai/gpt-oss-20b",
            name="GPT OSS 20B",
            api="openai-completions",
            provider="groq",
            baseUrl="https://api.groq.com/openai/v1",
            reasoning=true,
            input=["text"],
            cost=Dict("input"=>0.1, "output"=>0.5, "cacheRead"=>0, "cacheWrite"=>0),
            contextWindow=131072,
            maxTokens=32768,
            headers=nothing
        ),
        "openai/gpt-oss-120b" => Model(
            id="openai/gpt-oss-120b",
            name="GPT OSS 120B",
            api="openai-completions",
            provider="groq",
            baseUrl="https://api.groq.com/openai/v1",
            reasoning=true,
            input=["text"],
            cost=Dict("input"=>0.15, "output"=>0.75, "cacheRead"=>0, "cacheWrite"=>0),
            contextWindow=131072,
            maxTokens=32768,
            headers=nothing
        ),
        "qwen/qwen3-32b" => Model(
            id="qwen/qwen3-32b",
            name="Qwen3 32B",
            api="openai-completions",
            provider="groq",
            baseUrl="https://api.groq.com/openai/v1",
            reasoning=true,
            input=["text"],
            cost=Dict("input"=>0.29, "output"=>0.59, "cacheRead"=>0, "cacheWrite"=>0),
            contextWindow=131072,
            maxTokens=16384,
            headers=nothing
        ),
        "meta-llama/llama-4-scout-17b-16e-instruct" => Model(
            id="meta-llama/llama-4-scout-17b-16e-instruct",
            name="Llama 4 Scout 17B",
            api="openai-completions",
            provider="groq",
            baseUrl="https://api.groq.com/openai/v1",
            reasoning=false,
            input=["text", "image"],
            cost=Dict("input"=>0.11, "output"=>0.34, "cacheRead"=>0, "cacheWrite"=>0),
            contextWindow=131072,
            maxTokens=8192,
            headers=nothing
        ),
        "meta-llama/llama-4-maverick-17b-128e-instruct" => Model(
            id="meta-llama/llama-4-maverick-17b-128e-instruct",
            name="Llama 4 Maverick 17B",
            api="openai-completions",
            provider="groq",
            baseUrl="https://api.groq.com/openai/v1",
            reasoning=false,
            input=["text", "image"],
            cost=Dict("input"=>0.2, "output"=>0.6, "cacheRead"=>0, "cacheWrite"=>0),
            contextWindow=131072,
            maxTokens=8192,
            headers=nothing
        ),
    )

    # cerebras models
    _model_registry["cerebras"] = Dict{String,Model}(
        "qwen-3-235b-a22b-instruct-2507" => Model(
            id="qwen-3-235b-a22b-instruct-2507",
            name="Qwen 3 235B Instruct",
            api="openai-completions",
            provider="cerebras",
            baseUrl="https://api.cerebras.ai/v1",
            reasoning=false,
            input=["text"],
            cost=Dict("input"=>0.6, "output"=>1.2, "cacheRead"=>0, "cacheWrite"=>0),
            contextWindow=131000,
            maxTokens=32000,
            headers=nothing
        ),
        "zai-glm-4.6" => Model(
            id="zai-glm-4.6",
            name="Z.AI GLM-4.6",
            api="openai-completions",
            provider="cerebras",
            baseUrl="https://api.cerebras.ai/v1",
            reasoning=false,
            input=["text"],
            cost=Dict("input"=>0, "output"=>0, "cacheRead"=>0, "cacheWrite"=>0),
            contextWindow=131072,
            maxTokens=40960,
            headers=nothing
        ),
        "gpt-oss-120b" => Model(
            id="gpt-oss-120b",
            name="GPT OSS 120B",
            api="openai-completions",
            provider="cerebras",
            baseUrl="https://api.cerebras.ai/v1",
            reasoning=true,
            input=["text"],
            cost=Dict("input"=>0.25, "output"=>0.69, "cacheRead"=>0, "cacheWrite"=>0),
            contextWindow=131072,
            maxTokens=32768,
            headers=nothing
        ),
    )

    # xai models
    _model_registry["xai"] = Dict{String,Model}(
        "grok-4-fast-non-reasoning" => Model(
            id="grok-4-fast-non-reasoning",
            name="Grok 4 Fast (Non-Reasoning)",
            api="openai-completions",
            provider="xai",
            baseUrl="https://api.x.ai/v1",
            reasoning=false,
            input=["text", "image"],
            cost=Dict("input"=>0.2, "output"=>0.5, "cacheRead"=>0.05, "cacheWrite"=>0),
            contextWindow=2000000,
            maxTokens=30000,
            headers=nothing
        ),
        "grok-3-fast" => Model(
            id="grok-3-fast",
            name="Grok 3 Fast",
            api="openai-completions",
            provider="xai",
            baseUrl="https://api.x.ai/v1",
            reasoning=false,
            input=["text"],
            cost=Dict("input"=>5, "output"=>25, "cacheRead"=>1.25, "cacheWrite"=>0),
            contextWindow=131072,
            maxTokens=8192,
            headers=nothing
        ),
        "grok-4" => Model(
            id="grok-4",
            name="Grok 4",
            api="openai-completions",
            provider="xai",
            baseUrl="https://api.x.ai/v1",
            reasoning=true,
            input=["text"],
            cost=Dict("input"=>3, "output"=>15, "cacheRead"=>0.75, "cacheWrite"=>0),
            contextWindow=256000,
            maxTokens=64000,
            headers=nothing
        ),
        "grok-2-vision" => Model(
            id="grok-2-vision",
            name="Grok 2 Vision",
            api="openai-completions",
            provider="xai",
            baseUrl="https://api.x.ai/v1",
            reasoning=false,
            input=["text", "image"],
            cost=Dict("input"=>2, "output"=>10, "cacheRead"=>2, "cacheWrite"=>0),
            contextWindow=8192,
            maxTokens=4096,
            headers=nothing
        ),
        "grok-code-fast-1" => Model(
            id="grok-code-fast-1",
            name="Grok Code Fast 1",
            api="openai-completions",
            provider="xai",
            baseUrl="https://api.x.ai/v1",
            reasoning=true,
            input=["text"],
            cost=Dict("input"=>0.2, "output"=>1.5, "cacheRead"=>0.02, "cacheWrite"=>0),
            contextWindow=256000,
            maxTokens=10000,
            headers=nothing
        ),
        "grok-2" => Model(
            id="grok-2",
            name="Grok 2",
            api="openai-completions",
            provider="xai",
            baseUrl="https://api.x.ai/v1",
            reasoning=false,
            input=["text"],
            cost=Dict("input"=>2, "output"=>10, "cacheRead"=>2, "cacheWrite"=>0),
            contextWindow=131072,
            maxTokens=8192,
            headers=nothing
        ),
        "grok-3-mini-fast-latest" => Model(
            id="grok-3-mini-fast-latest",
            name="Grok 3 Mini Fast Latest",
            api="openai-completions",
            provider="xai",
            baseUrl="https://api.x.ai/v1",
            reasoning=true,
            input=["text"],
            cost=Dict("input"=>0.6, "output"=>4, "cacheRead"=>0.15, "cacheWrite"=>0),
            contextWindow=131072,
            maxTokens=8192,
            headers=nothing
        ),
        "grok-2-vision-1212" => Model(
            id="grok-2-vision-1212",
            name="Grok 2 Vision (1212)",
            api="openai-completions",
            provider="xai",
            baseUrl="https://api.x.ai/v1",
            reasoning=false,
            input=["text", "image"],
            cost=Dict("input"=>2, "output"=>10, "cacheRead"=>2, "cacheWrite"=>0),
            contextWindow=8192,
            maxTokens=4096,
            headers=nothing
        ),
        "grok-3" => Model(
            id="grok-3",
            name="Grok 3",
            api="openai-completions",
            provider="xai",
            baseUrl="https://api.x.ai/v1",
            reasoning=false,
            input=["text"],
            cost=Dict("input"=>3, "output"=>15, "cacheRead"=>0.75, "cacheWrite"=>0),
            contextWindow=131072,
            maxTokens=8192,
            headers=nothing
        ),
        "grok-4-fast" => Model(
            id="grok-4-fast",
            name="Grok 4 Fast",
            api="openai-completions",
            provider="xai",
            baseUrl="https://api.x.ai/v1",
            reasoning=true,
            input=["text", "image"],
            cost=Dict("input"=>0.2, "output"=>0.5, "cacheRead"=>0.05, "cacheWrite"=>0),
            contextWindow=2000000,
            maxTokens=30000,
            headers=nothing
        ),
        "grok-2-latest" => Model(
            id="grok-2-latest",
            name="Grok 2 Latest",
            api="openai-completions",
            provider="xai",
            baseUrl="https://api.x.ai/v1",
            reasoning=false,
            input=["text"],
            cost=Dict("input"=>2, "output"=>10, "cacheRead"=>2, "cacheWrite"=>0),
            contextWindow=131072,
            maxTokens=8192,
            headers=nothing
        ),
        "grok-4-1-fast" => Model(
            id="grok-4-1-fast",
            name="Grok 4.1 Fast",
            api="openai-completions",
            provider="xai",
            baseUrl="https://api.x.ai/v1",
            reasoning=true,
            input=["text", "image"],
            cost=Dict("input"=>0.2, "output"=>0.5, "cacheRead"=>0.05, "cacheWrite"=>0),
            contextWindow=2000000,
            maxTokens=30000,
            headers=nothing
        ),
        "grok-2-1212" => Model(
            id="grok-2-1212",
            name="Grok 2 (1212)",
            api="openai-completions",
            provider="xai",
            baseUrl="https://api.x.ai/v1",
            reasoning=false,
            input=["text"],
            cost=Dict("input"=>2, "output"=>10, "cacheRead"=>2, "cacheWrite"=>0),
            contextWindow=131072,
            maxTokens=8192,
            headers=nothing
        ),
        "grok-3-fast-latest" => Model(
            id="grok-3-fast-latest",
            name="Grok 3 Fast Latest",
            api="openai-completions",
            provider="xai",
            baseUrl="https://api.x.ai/v1",
            reasoning=false,
            input=["text"],
            cost=Dict("input"=>5, "output"=>25, "cacheRead"=>1.25, "cacheWrite"=>0),
            contextWindow=131072,
            maxTokens=8192,
            headers=nothing
        ),
        "grok-3-latest" => Model(
            id="grok-3-latest",
            name="Grok 3 Latest",
            api="openai-completions",
            provider="xai",
            baseUrl="https://api.x.ai/v1",
            reasoning=false,
            input=["text"],
            cost=Dict("input"=>3, "output"=>15, "cacheRead"=>0.75, "cacheWrite"=>0),
            contextWindow=131072,
            maxTokens=8192,
            headers=nothing
        ),
        "grok-2-vision-latest" => Model(
            id="grok-2-vision-latest",
            name="Grok 2 Vision Latest",
            api="openai-completions",
            provider="xai",
            baseUrl="https://api.x.ai/v1",
            reasoning=false,
            input=["text", "image"],
            cost=Dict("input"=>2, "output"=>10, "cacheRead"=>2, "cacheWrite"=>0),
            contextWindow=8192,
            maxTokens=4096,
            headers=nothing
        ),
        "grok-vision-beta" => Model(
            id="grok-vision-beta",
            name="Grok Vision Beta",
            api="openai-completions",
            provider="xai",
            baseUrl="https://api.x.ai/v1",
            reasoning=false,
            input=["text", "image"],
            cost=Dict("input"=>5, "output"=>15, "cacheRead"=>5, "cacheWrite"=>0),
            contextWindow=8192,
            maxTokens=4096,
            headers=nothing
        ),
        "grok-3-mini" => Model(
            id="grok-3-mini",
            name="Grok 3 Mini",
            api="openai-completions",
            provider="xai",
            baseUrl="https://api.x.ai/v1",
            reasoning=true,
            input=["text"],
            cost=Dict("input"=>0.3, "output"=>0.5, "cacheRead"=>0.075, "cacheWrite"=>0),
            contextWindow=131072,
            maxTokens=8192,
            headers=nothing
        ),
        "grok-beta" => Model(
            id="grok-beta",
            name="Grok Beta",
            api="openai-completions",
            provider="xai",
            baseUrl="https://api.x.ai/v1",
            reasoning=false,
            input=["text"],
            cost=Dict("input"=>5, "output"=>15, "cacheRead"=>5, "cacheWrite"=>0),
            contextWindow=131072,
            maxTokens=4096,
            headers=nothing
        ),
        "grok-3-mini-latest" => Model(
            id="grok-3-mini-latest",
            name="Grok 3 Mini Latest",
            api="openai-completions",
            provider="xai",
            baseUrl="https://api.x.ai/v1",
            reasoning=true,
            input=["text"],
            cost=Dict("input"=>0.3, "output"=>0.5, "cacheRead"=>0.075, "cacheWrite"=>0),
            contextWindow=131072,
            maxTokens=8192,
            headers=nothing
        ),
        "grok-4-1-fast-non-reasoning" => Model(
            id="grok-4-1-fast-non-reasoning",
            name="Grok 4.1 Fast (Non-Reasoning)",
            api="openai-completions",
            provider="xai",
            baseUrl="https://api.x.ai/v1",
            reasoning=false,
            input=["text", "image"],
            cost=Dict("input"=>0.2, "output"=>0.5, "cacheRead"=>0.05, "cacheWrite"=>0),
            contextWindow=2000000,
            maxTokens=30000,
            headers=nothing
        ),
        "grok-3-mini-fast" => Model(
            id="grok-3-mini-fast",
            name="Grok 3 Mini Fast",
            api="openai-completions",
            provider="xai",
            baseUrl="https://api.x.ai/v1",
            reasoning=true,
            input=["text"],
            cost=Dict("input"=>0.6, "output"=>4, "cacheRead"=>0.15, "cacheWrite"=>0),
            contextWindow=131072,
            maxTokens=8192,
            headers=nothing
        ),
    )

    # zai models
    _model_registry["zai"] = Dict{String,Model}(
        "glm-4.5-flash" => Model(
            id="glm-4.5-flash",
            name="GLM-4.5-Flash",
            api="anthropic-messages",
            provider="zai",
            baseUrl="https://api.z.ai/api/anthropic",
            reasoning=true,
            input=["text"],
            cost=Dict("input"=>0, "output"=>0, "cacheRead"=>0, "cacheWrite"=>0),
            contextWindow=131072,
            maxTokens=98304,
            headers=nothing
        ),
        "glm-4.5" => Model(
            id="glm-4.5",
            name="GLM-4.5",
            api="anthropic-messages",
            provider="zai",
            baseUrl="https://api.z.ai/api/anthropic",
            reasoning=true,
            input=["text"],
            cost=Dict("input"=>0.6, "output"=>2.2, "cacheRead"=>0.11, "cacheWrite"=>0),
            contextWindow=131072,
            maxTokens=98304,
            headers=nothing
        ),
        "glm-4.5-air" => Model(
            id="glm-4.5-air",
            name="GLM-4.5-Air",
            api="anthropic-messages",
            provider="zai",
            baseUrl="https://api.z.ai/api/anthropic",
            reasoning=true,
            input=["text"],
            cost=Dict("input"=>0.2, "output"=>1.1, "cacheRead"=>0.03, "cacheWrite"=>0),
            contextWindow=131072,
            maxTokens=98304,
            headers=nothing
        ),
        "glm-4.5v" => Model(
            id="glm-4.5v",
            name="GLM 4.5V",
            api="anthropic-messages",
            provider="zai",
            baseUrl="https://api.z.ai/api/anthropic",
            reasoning=true,
            input=["text", "image"],
            cost=Dict("input"=>0.6, "output"=>1.8, "cacheRead"=>0, "cacheWrite"=>0),
            contextWindow=64000,
            maxTokens=16384,
            headers=nothing
        ),
        "glm-4.6" => Model(
            id="glm-4.6",
            name="GLM-4.6",
            api="anthropic-messages",
            provider="zai",
            baseUrl="https://api.z.ai/api/anthropic",
            reasoning=true,
            input=["text"],
            cost=Dict("input"=>0.6, "output"=>2.2, "cacheRead"=>0.11, "cacheWrite"=>0),
            contextWindow=204800,
            maxTokens=131072,
            headers=nothing
        ),
    )

    # openrouter models
    _model_registry["openrouter"] = Dict{String,Model}(
        "arcee-ai/trinity-mini:free" => Model(
            id="arcee-ai/trinity-mini:free",
            name="Arcee AI: Trinity Mini (free)",
            api="openai-completions",
            provider="openrouter",
            baseUrl="https://openrouter.ai/api/v1",
            reasoning=true,
            input=["text"],
            cost=Dict("input"=>0, "output"=>0, "cacheRead"=>0, "cacheWrite"=>0),
            contextWindow=131072,
            maxTokens=4096,
            headers=nothing
        ),
        "arcee-ai/trinity-mini" => Model(
            id="arcee-ai/trinity-mini",
            name="Arcee AI: Trinity Mini",
            api="openai-completions",
            provider="openrouter",
            baseUrl="https://openrouter.ai/api/v1",
            reasoning=true,
            input=["text"],
            cost=Dict("input"=>0.045, "output"=>0.15, "cacheRead"=>0, "cacheWrite"=>0),
            contextWindow=131072,
            maxTokens=4096,
            headers=nothing
        ),
        "deepseek/deepseek-v3.2" => Model(
            id="deepseek/deepseek-v3.2",
            name="DeepSeek: DeepSeek V3.2",
            api="openai-completions",
            provider="openrouter",
            baseUrl="https://openrouter.ai/api/v1",
            reasoning=true,
            input=["text"],
            cost=Dict("input"=>0.28, "output"=>0.39999999999999997, "cacheRead"=>0, "cacheWrite"=>0),
            contextWindow=163840,
            maxTokens=65536,
            headers=nothing
        ),
        "prime-intellect/intellect-3" => Model(
            id="prime-intellect/intellect-3",
            name="Prime Intellect: INTELLECT-3",
            api="openai-completions",
            provider="openrouter",
            baseUrl="https://openrouter.ai/api/v1",
            reasoning=true,
            input=["text"],
            cost=Dict("input"=>0.19999999999999998, "output"=>1.1, "cacheRead"=>0, "cacheWrite"=>0),
            contextWindow=131072,
            maxTokens=131072,
            headers=nothing
        ),
        "tngtech/tng-r1t-chimera:free" => Model(
            id="tngtech/tng-r1t-chimera:free",
            name="TNG: R1T Chimera (free)",
            api="openai-completions",
            provider="openrouter",
            baseUrl="https://openrouter.ai/api/v1",
            reasoning=true,
            input=["text"],
            cost=Dict("input"=>0, "output"=>0, "cacheRead"=>0, "cacheWrite"=>0),
            contextWindow=163840,
            maxTokens=163840,
            headers=nothing
        ),
        "tngtech/tng-r1t-chimera" => Model(
            id="tngtech/tng-r1t-chimera",
            name="TNG: R1T Chimera",
            api="openai-completions",
            provider="openrouter",
            baseUrl="https://openrouter.ai/api/v1",
            reasoning=true,
            input=["text"],
            cost=Dict("input"=>0.3, "output"=>1.2, "cacheRead"=>0, "cacheWrite"=>0),
            contextWindow=163840,
            maxTokens=163840,
            headers=nothing
        ),
        "anthropic/claude-opus-4.5" => Model(
            id="anthropic/claude-opus-4.5",
            name="Anthropic: Claude Opus 4.5",
            api="openai-completions",
            provider="openrouter",
            baseUrl="https://openrouter.ai/api/v1",
            reasoning=true,
            input=["text", "image"],
            cost=Dict("input"=>5, "output"=>25, "cacheRead"=>0.5, "cacheWrite"=>6.25),
            contextWindow=200000,
            maxTokens=64000,
            headers=nothing
        ),
        "openrouter/bert-nebulon-alpha" => Model(
            id="openrouter/bert-nebulon-alpha",
            name="Bert-Nebulon Alpha",
            api="openai-completions",
            provider="openrouter",
            baseUrl="https://openrouter.ai/api/v1",
            reasoning=false,
            input=["text", "image"],
            cost=Dict("input"=>0, "output"=>0, "cacheRead"=>0, "cacheWrite"=>0),
            contextWindow=256000,
            maxTokens=4096,
            headers=nothing
        ),
        "allenai/olmo-3-7b-instruct" => Model(
            id="allenai/olmo-3-7b-instruct",
            name="AllenAI: Olmo 3 7B Instruct",
            api="openai-completions",
            provider="openrouter",
            baseUrl="https://openrouter.ai/api/v1",
            reasoning=false,
            input=["text"],
            cost=Dict("input"=>0.09999999999999999, "output"=>0.19999999999999998, "cacheRead"=>0, "cacheWrite"=>0),
            contextWindow=65536,
            maxTokens=65536,
            headers=nothing
        ),
        "x-ai/grok-4.1-fast:free" => Model(
            id="x-ai/grok-4.1-fast:free",
            name="xAI: Grok 4.1 Fast (free)",
            api="openai-completions",
            provider="openrouter",
            baseUrl="https://openrouter.ai/api/v1",
            reasoning=true,
            input=["text", "image"],
            cost=Dict("input"=>0, "output"=>0, "cacheRead"=>0, "cacheWrite"=>0),
            contextWindow=2000000,
            maxTokens=30000,
            headers=nothing
        ),
        "google/gemini-3-pro-preview" => Model(
            id="google/gemini-3-pro-preview",
            name="Google: Gemini 3 Pro Preview",
            api="openai-completions",
            provider="openrouter",
            baseUrl="https://openrouter.ai/api/v1",
            reasoning=true,
            input=["text", "image"],
            cost=Dict("input"=>2, "output"=>12, "cacheRead"=>0.19999999999999998, "cacheWrite"=>2.375),
            contextWindow=1048576,
            maxTokens=65536,
            headers=nothing
        ),
        "openai/gpt-5.1" => Model(
            id="openai/gpt-5.1",
            name="OpenAI: GPT-5.1",
            api="openai-completions",
            provider="openrouter",
            baseUrl="https://openrouter.ai/api/v1",
            reasoning=true,
            input=["text", "image"],
            cost=Dict("input"=>1.25, "output"=>10, "cacheRead"=>0.125, "cacheWrite"=>0),
            contextWindow=400000,
            maxTokens=128000,
            headers=nothing
        ),
        "openai/gpt-5.1-chat" => Model(
            id="openai/gpt-5.1-chat",
            name="OpenAI: GPT-5.1 Chat",
            api="openai-completions",
            provider="openrouter",
            baseUrl="https://openrouter.ai/api/v1",
            reasoning=false,
            input=["text", "image"],
            cost=Dict("input"=>1.25, "output"=>10, "cacheRead"=>0.125, "cacheWrite"=>0),
            contextWindow=128000,
            maxTokens=16384,
            headers=nothing
        ),
        "openai/gpt-5.1-codex" => Model(
            id="openai/gpt-5.1-codex",
            name="OpenAI: GPT-5.1-Codex",
            api="openai-completions",
            provider="openrouter",
            baseUrl="https://openrouter.ai/api/v1",
            reasoning=true,
            input=["text", "image"],
            cost=Dict("input"=>1.25, "output"=>10, "cacheRead"=>0.125, "cacheWrite"=>0),
            contextWindow=400000,
            maxTokens=128000,
            headers=nothing
        ),
        "openai/gpt-5.1-codex-mini" => Model(
            id="openai/gpt-5.1-codex-mini",
            name="OpenAI: GPT-5.1-Codex-Mini",
            api="openai-completions",
            provider="openrouter",
            baseUrl="https://openrouter.ai/api/v1",
            reasoning=true,
            input=["text", "image"],
            cost=Dict("input"=>0.25, "output"=>2, "cacheRead"=>0.024999999999999998, "cacheWrite"=>0),
            contextWindow=400000,
            maxTokens=100000,
            headers=nothing
        ),
        "kwaipilot/kat-coder-pro:free" => Model(
            id="kwaipilot/kat-coder-pro:free",
            name="Kwaipilot: KAT-Coder-Pro V1 (free)",
            api="openai-completions",
            provider="openrouter",
            baseUrl="https://openrouter.ai/api/v1",
            reasoning=false,
            input=["text"],
            cost=Dict("input"=>0, "output"=>0, "cacheRead"=>0, "cacheWrite"=>0),
            contextWindow=256000,
            maxTokens=32768,
            headers=nothing
        ),
        "moonshotai/kimi-k2-thinking" => Model(
            id="moonshotai/kimi-k2-thinking",
            name="MoonshotAI: Kimi K2 Thinking",
            api="openai-completions",
            provider="openrouter",
            baseUrl="https://openrouter.ai/api/v1",
            reasoning=true,
            input=["text"],
            cost=Dict("input"=>0.44999999999999996, "output"=>2.35, "cacheRead"=>0, "cacheWrite"=>0),
            contextWindow=262144,
            maxTokens=16384,
            headers=nothing
        ),
        "amazon/nova-premier-v1" => Model(
            id="amazon/nova-premier-v1",
            name="Amazon: Nova Premier 1.0",
            api="openai-completions",
            provider="openrouter",
            baseUrl="https://openrouter.ai/api/v1",
            reasoning=false,
            input=["text", "image"],
            cost=Dict("input"=>2.5, "output"=>12.5, "cacheRead"=>0.625, "cacheWrite"=>0),
            contextWindow=1000000,
            maxTokens=32000,
            headers=nothing
        ),
        "mistralai/voxtral-small-24b-2507" => Model(
            id="mistralai/voxtral-small-24b-2507",
            name="Mistral: Voxtral Small 24B 2507",
            api="openai-completions",
            provider="openrouter",
            baseUrl="https://openrouter.ai/api/v1",
            reasoning=false,
            input=["text"],
            cost=Dict("input"=>0.09999999999999999, "output"=>0.3, "cacheRead"=>0, "cacheWrite"=>0),
            contextWindow=32000,
            maxTokens=4096,
            headers=nothing
        ),
        "openai/gpt-oss-safeguard-20b" => Model(
            id="openai/gpt-oss-safeguard-20b",
            name="OpenAI: gpt-oss-safeguard-20b",
            api="openai-completions",
            provider="openrouter",
            baseUrl="https://openrouter.ai/api/v1",
            reasoning=true,
            input=["text"],
            cost=Dict("input"=>0.075, "output"=>0.3, "cacheRead"=>0.037, "cacheWrite"=>0),
            contextWindow=131072,
            maxTokens=65536,
            headers=nothing
        ),
        "nvidia/nemotron-nano-12b-v2-vl:free" => Model(
            id="nvidia/nemotron-nano-12b-v2-vl:free",
            name="NVIDIA: Nemotron Nano 12B 2 VL (free)",
            api="openai-completions",
            provider="openrouter",
            baseUrl="https://openrouter.ai/api/v1",
            reasoning=true,
            input=["text", "image"],
            cost=Dict("input"=>0, "output"=>0, "cacheRead"=>0, "cacheWrite"=>0),
            contextWindow=128000,
            maxTokens=128000,
            headers=nothing
        ),
        "minimax/minimax-m2" => Model(
            id="minimax/minimax-m2",
            name="MiniMax: MiniMax M2",
            api="openai-completions",
            provider="openrouter",
            baseUrl="https://openrouter.ai/api/v1",
            reasoning=true,
            input=["text"],
            cost=Dict("input"=>0.255, "output"=>1.02, "cacheRead"=>0, "cacheWrite"=>0),
            contextWindow=204800,
            maxTokens=131072,
            headers=nothing
        ),
        "deepcogito/cogito-v2-preview-llama-405b" => Model(
            id="deepcogito/cogito-v2-preview-llama-405b",
            name="Deep Cogito: Cogito V2 Preview Llama 405B",
            api="openai-completions",
            provider="openrouter",
            baseUrl="https://openrouter.ai/api/v1",
            reasoning=true,
            input=["text"],
            cost=Dict("input"=>3.5, "output"=>3.5, "cacheRead"=>0, "cacheWrite"=>0),
            contextWindow=32768,
            maxTokens=4096,
            headers=nothing
        ),
        "openai/gpt-5-image-mini" => Model(
            id="openai/gpt-5-image-mini",
            name="OpenAI: GPT-5 Image Mini",
            api="openai-completions",
            provider="openrouter",
            baseUrl="https://openrouter.ai/api/v1",
            reasoning=true,
            input=["text", "image"],
            cost=Dict("input"=>2.5, "output"=>2, "cacheRead"=>0.25, "cacheWrite"=>0),
            contextWindow=400000,
            maxTokens=128000,
            headers=nothing
        ),
        "anthropic/claude-haiku-4.5" => Model(
            id="anthropic/claude-haiku-4.5",
            name="Anthropic: Claude Haiku 4.5",
            api="openai-completions",
            provider="openrouter",
            baseUrl="https://openrouter.ai/api/v1",
            reasoning=true,
            input=["text", "image"],
            cost=Dict("input"=>1, "output"=>5, "cacheRead"=>0.09999999999999999, "cacheWrite"=>1.25),
            contextWindow=200000,
            maxTokens=64000,
            headers=nothing
        ),
        "qwen/qwen3-vl-8b-thinking" => Model(
            id="qwen/qwen3-vl-8b-thinking",
            name="Qwen: Qwen3 VL 8B Thinking",
            api="openai-completions",
            provider="openrouter",
            baseUrl="https://openrouter.ai/api/v1",
            reasoning=true,
            input=["text", "image"],
            cost=Dict("input"=>0.18, "output"=>2.0999999999999996, "cacheRead"=>0, "cacheWrite"=>0),
            contextWindow=256000,
            maxTokens=32768,
            headers=nothing
        ),
        "qwen/qwen3-vl-8b-instruct" => Model(
            id="qwen/qwen3-vl-8b-instruct",
            name="Qwen: Qwen3 VL 8B Instruct",
            api="openai-completions",
            provider="openrouter",
            baseUrl="https://openrouter.ai/api/v1",
            reasoning=false,
            input=["text", "image"],
            cost=Dict("input"=>0.064, "output"=>0.39999999999999997, "cacheRead"=>0, "cacheWrite"=>0),
            contextWindow=131072,
            maxTokens=32768,
            headers=nothing
        ),
        "openai/gpt-5-image" => Model(
            id="openai/gpt-5-image",
            name="OpenAI: GPT-5 Image",
            api="openai-completions",
            provider="openrouter",
            baseUrl="https://openrouter.ai/api/v1",
            reasoning=true,
            input=["text", "image"],
            cost=Dict("input"=>10, "output"=>10, "cacheRead"=>1.25, "cacheWrite"=>0),
            contextWindow=400000,
            maxTokens=128000,
            headers=nothing
        ),
        "openai/o3-deep-research" => Model(
            id="openai/o3-deep-research",
            name="OpenAI: o3 Deep Research",
            api="openai-completions",
            provider="openrouter",
            baseUrl="https://openrouter.ai/api/v1",
            reasoning=true,
            input=["text", "image"],
            cost=Dict("input"=>10, "output"=>40, "cacheRead"=>2.5, "cacheWrite"=>0),
            contextWindow=200000,
            maxTokens=100000,
            headers=nothing
        ),
        "openai/o4-mini-deep-research" => Model(
            id="openai/o4-mini-deep-research",
            name="OpenAI: o4 Mini Deep Research",
            api="openai-completions",
            provider="openrouter",
            baseUrl="https://openrouter.ai/api/v1",
            reasoning=true,
            input=["text", "image"],
            cost=Dict("input"=>2, "output"=>8, "cacheRead"=>0.5, "cacheWrite"=>0),
            contextWindow=200000,
            maxTokens=100000,
            headers=nothing
        ),
        "nvidia/llama-3.3-nemotron-super-49b-v1.5" => Model(
            id="nvidia/llama-3.3-nemotron-super-49b-v1.5",
            name="NVIDIA: Llama 3.3 Nemotron Super 49B V1.5",
            api="openai-completions",
            provider="openrouter",
            baseUrl="https://openrouter.ai/api/v1",
            reasoning=true,
            input=["text"],
            cost=Dict("input"=>0.09999999999999999, "output"=>0.39999999999999997, "cacheRead"=>0, "cacheWrite"=>0),
            contextWindow=131072,
            maxTokens=4096,
            headers=nothing
        ),
        "qwen/qwen3-vl-30b-a3b-thinking" => Model(
            id="qwen/qwen3-vl-30b-a3b-thinking",
            name="Qwen: Qwen3 VL 30B A3B Thinking",
            api="openai-completions",
            provider="openrouter",
            baseUrl="https://openrouter.ai/api/v1",
            reasoning=true,
            input=["text", "image"],
            cost=Dict("input"=>0.16, "output"=>0.7999999999999999, "cacheRead"=>0, "cacheWrite"=>0),
            contextWindow=131072,
            maxTokens=32768,
            headers=nothing
        ),
        "qwen/qwen3-vl-30b-a3b-instruct" => Model(
            id="qwen/qwen3-vl-30b-a3b-instruct",
            name="Qwen: Qwen3 VL 30B A3B Instruct",
            api="openai-completions",
            provider="openrouter",
            baseUrl="https://openrouter.ai/api/v1",
            reasoning=false,
            input=["text", "image"],
            cost=Dict("input"=>0.15, "output"=>0.6, "cacheRead"=>0, "cacheWrite"=>0),
            contextWindow=262144,
            maxTokens=4096,
            headers=nothing
        ),
        "openai/gpt-5-pro" => Model(
            id="openai/gpt-5-pro",
            name="OpenAI: GPT-5 Pro",
            api="openai-completions",
            provider="openrouter",
            baseUrl="https://openrouter.ai/api/v1",
            reasoning=true,
            input=["text", "image"],
            cost=Dict("input"=>15, "output"=>120, "cacheRead"=>0, "cacheWrite"=>0),
            contextWindow=400000,
            maxTokens=128000,
            headers=nothing
        ),
        "z-ai/glm-4.6" => Model(
            id="z-ai/glm-4.6",
            name="Z.AI: GLM 4.6",
            api="openai-completions",
            provider="openrouter",
            baseUrl="https://openrouter.ai/api/v1",
            reasoning=true,
            input=["text"],
            cost=Dict("input"=>0.39999999999999997, "output"=>1.75, "cacheRead"=>0, "cacheWrite"=>0),
            contextWindow=202752,
            maxTokens=202752,
            headers=nothing
        ),
        "z-ai/glm-4.6:exacto" => Model(
            id="z-ai/glm-4.6:exacto",
            name="Z.AI: GLM 4.6 (exacto)",
            api="openai-completions",
            provider="openrouter",
            baseUrl="https://openrouter.ai/api/v1",
            reasoning=true,
            input=["text"],
            cost=Dict("input"=>0.44, "output"=>1.76, "cacheRead"=>0, "cacheWrite"=>0),
            contextWindow=204800,
            maxTokens=131072,
            headers=nothing
        ),
        "anthropic/claude-sonnet-4.5" => Model(
            id="anthropic/claude-sonnet-4.5",
            name="Anthropic: Claude Sonnet 4.5",
            api="openai-completions",
            provider="openrouter",
            baseUrl="https://openrouter.ai/api/v1",
            reasoning=true,
            input=["text", "image"],
            cost=Dict("input"=>3, "output"=>15, "cacheRead"=>0.3, "cacheWrite"=>3.75),
            contextWindow=1000000,
            maxTokens=64000,
            headers=nothing
        ),
        "deepseek/deepseek-v3.2-exp" => Model(
            id="deepseek/deepseek-v3.2-exp",
            name="DeepSeek: DeepSeek V3.2 Exp",
            api="openai-completions",
            provider="openrouter",
            baseUrl="https://openrouter.ai/api/v1",
            reasoning=true,
            input=["text"],
            cost=Dict("input"=>0.21, "output"=>0.32, "cacheRead"=>0.16799999999999998, "cacheWrite"=>0),
            contextWindow=163840,
            maxTokens=4096,
            headers=nothing
        ),
        "google/gemini-2.5-flash-preview-09-2025" => Model(
            id="google/gemini-2.5-flash-preview-09-2025",
            name="Google: Gemini 2.5 Flash Preview 09-2025",
            api="openai-completions",
            provider="openrouter",
            baseUrl="https://openrouter.ai/api/v1",
            reasoning=true,
            input=["text", "image"],
            cost=Dict("input"=>0.3, "output"=>2.5, "cacheRead"=>0.075, "cacheWrite"=>0.3833),
            contextWindow=1048576,
            maxTokens=65536,
            headers=nothing
        ),
        "google/gemini-2.5-flash-lite-preview-09-2025" => Model(
            id="google/gemini-2.5-flash-lite-preview-09-2025",
            name="Google: Gemini 2.5 Flash Lite Preview 09-2025",
            api="openai-completions",
            provider="openrouter",
            baseUrl="https://openrouter.ai/api/v1",
            reasoning=true,
            input=["text", "image"],
            cost=Dict("input"=>0.09999999999999999, "output"=>0.39999999999999997, "cacheRead"=>0, "cacheWrite"=>0),
            contextWindow=1048576,
            maxTokens=65536,
            headers=nothing
        ),
        "qwen/qwen3-vl-235b-a22b-thinking" => Model(
            id="qwen/qwen3-vl-235b-a22b-thinking",
            name="Qwen: Qwen3 VL 235B A22B Thinking",
            api="openai-completions",
            provider="openrouter",
            baseUrl="https://openrouter.ai/api/v1",
            reasoning=true,
            input=["text", "image"],
            cost=Dict("input"=>0.3, "output"=>1.2, "cacheRead"=>0, "cacheWrite"=>0),
            contextWindow=262144,
            maxTokens=262144,
            headers=nothing
        ),
        "qwen/qwen3-vl-235b-a22b-instruct" => Model(
            id="qwen/qwen3-vl-235b-a22b-instruct",
            name="Qwen: Qwen3 VL 235B A22B Instruct",
            api="openai-completions",
            provider="openrouter",
            baseUrl="https://openrouter.ai/api/v1",
            reasoning=false,
            input=["text", "image"],
            cost=Dict("input"=>0.21, "output"=>1.9, "cacheRead"=>0, "cacheWrite"=>0),
            contextWindow=131072,
            maxTokens=32768,
            headers=nothing
        ),
        "qwen/qwen3-max" => Model(
            id="qwen/qwen3-max",
            name="Qwen: Qwen3 Max",
            api="openai-completions",
            provider="openrouter",
            baseUrl="https://openrouter.ai/api/v1",
            reasoning=false,
            input=["text"],
            cost=Dict("input"=>1.2, "output"=>6, "cacheRead"=>0.24, "cacheWrite"=>0),
            contextWindow=256000,
            maxTokens=32768,
            headers=nothing
        ),
        "qwen/qwen3-coder-plus" => Model(
            id="qwen/qwen3-coder-plus",
            name="Qwen: Qwen3 Coder Plus",
            api="openai-completions",
            provider="openrouter",
            baseUrl="https://openrouter.ai/api/v1",
            reasoning=false,
            input=["text"],
            cost=Dict("input"=>1, "output"=>5, "cacheRead"=>0.09999999999999999, "cacheWrite"=>0),
            contextWindow=128000,
            maxTokens=65536,
            headers=nothing
        ),
        "openai/gpt-5-codex" => Model(
            id="openai/gpt-5-codex",
            name="OpenAI: GPT-5 Codex",
            api="openai-completions",
            provider="openrouter",
            baseUrl="https://openrouter.ai/api/v1",
            reasoning=true,
            input=["text", "image"],
            cost=Dict("input"=>1.25, "output"=>10, "cacheRead"=>0.125, "cacheWrite"=>0),
            contextWindow=400000,
            maxTokens=128000,
            headers=nothing
        ),
        "deepseek/deepseek-v3.1-terminus" => Model(
            id="deepseek/deepseek-v3.1-terminus",
            name="DeepSeek: DeepSeek V3.1 Terminus",
            api="openai-completions",
            provider="openrouter",
            baseUrl="https://openrouter.ai/api/v1",
            reasoning=true,
            input=["text"],
            cost=Dict("input"=>0.21, "output"=>0.7899999999999999, "cacheRead"=>0.16799999999999998, "cacheWrite"=>0),
            contextWindow=163840,
            maxTokens=4096,
            headers=nothing
        ),
        "deepseek/deepseek-v3.1-terminus:exacto" => Model(
            id="deepseek/deepseek-v3.1-terminus:exacto",
            name="DeepSeek: DeepSeek V3.1 Terminus (exacto)",
            api="openai-completions",
            provider="openrouter",
            baseUrl="https://openrouter.ai/api/v1",
            reasoning=true,
            input=["text"],
            cost=Dict("input"=>0.216, "output"=>0.7999999999999999, "cacheRead"=>0, "cacheWrite"=>0),
            contextWindow=131072,
            maxTokens=65536,
            headers=nothing
        ),
        "x-ai/grok-4-fast" => Model(
            id="x-ai/grok-4-fast",
            name="xAI: Grok 4 Fast",
            api="openai-completions",
            provider="openrouter",
            baseUrl="https://openrouter.ai/api/v1",
            reasoning=true,
            input=["text", "image"],
            cost=Dict("input"=>0.19999999999999998, "output"=>0.5, "cacheRead"=>0.049999999999999996, "cacheWrite"=>0),
            contextWindow=2000000,
            maxTokens=30000,
            headers=nothing
        ),
        "alibaba/tongyi-deepresearch-30b-a3b:free" => Model(
            id="alibaba/tongyi-deepresearch-30b-a3b:free",
            name="Tongyi DeepResearch 30B A3B (free)",
            api="openai-completions",
            provider="openrouter",
            baseUrl="https://openrouter.ai/api/v1",
            reasoning=true,
            input=["text"],
            cost=Dict("input"=>0, "output"=>0, "cacheRead"=>0, "cacheWrite"=>0),
            contextWindow=131072,
            maxTokens=131072,
            headers=nothing
        ),
        "alibaba/tongyi-deepresearch-30b-a3b" => Model(
            id="alibaba/tongyi-deepresearch-30b-a3b",
            name="Tongyi DeepResearch 30B A3B",
            api="openai-completions",
            provider="openrouter",
            baseUrl="https://openrouter.ai/api/v1",
            reasoning=true,
            input=["text"],
            cost=Dict("input"=>0.09, "output"=>0.39999999999999997, "cacheRead"=>0, "cacheWrite"=>0),
            contextWindow=131072,
            maxTokens=131072,
            headers=nothing
        ),
        "qwen/qwen3-coder-flash" => Model(
            id="qwen/qwen3-coder-flash",
            name="Qwen: Qwen3 Coder Flash",
            api="openai-completions",
            provider="openrouter",
            baseUrl="https://openrouter.ai/api/v1",
            reasoning=false,
            input=["text"],
            cost=Dict("input"=>0.3, "output"=>1.5, "cacheRead"=>0.08, "cacheWrite"=>0),
            contextWindow=128000,
            maxTokens=65536,
            headers=nothing
        ),
        "qwen/qwen3-next-80b-a3b-thinking" => Model(
            id="qwen/qwen3-next-80b-a3b-thinking",
            name="Qwen: Qwen3 Next 80B A3B Thinking",
            api="openai-completions",
            provider="openrouter",
            baseUrl="https://openrouter.ai/api/v1",
            reasoning=true,
            input=["text"],
            cost=Dict("input"=>0.12, "output"=>1.2, "cacheRead"=>0, "cacheWrite"=>0),
            contextWindow=131072,
            maxTokens=32768,
            headers=nothing
        ),
        "qwen/qwen3-next-80b-a3b-instruct" => Model(
            id="qwen/qwen3-next-80b-a3b-instruct",
            name="Qwen: Qwen3 Next 80B A3B Instruct",
            api="openai-completions",
            provider="openrouter",
            baseUrl="https://openrouter.ai/api/v1",
            reasoning=false,
            input=["text"],
            cost=Dict("input"=>0.09999999999999999, "output"=>0.7999999999999999, "cacheRead"=>0, "cacheWrite"=>0),
            contextWindow=262144,
            maxTokens=262144,
            headers=nothing
        ),
        "meituan/longcat-flash-chat:free" => Model(
            id="meituan/longcat-flash-chat:free",
            name="Meituan: LongCat Flash Chat (free)",
            api="openai-completions",
            provider="openrouter",
            baseUrl="https://openrouter.ai/api/v1",
            reasoning=false,
            input=["text"],
            cost=Dict("input"=>0, "output"=>0, "cacheRead"=>0, "cacheWrite"=>0),
            contextWindow=131072,
            maxTokens=131072,
            headers=nothing
        ),
        "qwen/qwen-plus-2025-07-28" => Model(
            id="qwen/qwen-plus-2025-07-28",
            name="Qwen: Qwen Plus 0728",
            api="openai-completions",
            provider="openrouter",
            baseUrl="https://openrouter.ai/api/v1",
            reasoning=false,
            input=["text"],
            cost=Dict("input"=>0.39999999999999997, "output"=>1.2, "cacheRead"=>0, "cacheWrite"=>0),
            contextWindow=1000000,
            maxTokens=32768,
            headers=nothing
        ),
        "qwen/qwen-plus-2025-07-28:thinking" => Model(
            id="qwen/qwen-plus-2025-07-28:thinking",
            name="Qwen: Qwen Plus 0728 (thinking)",
            api="openai-completions",
            provider="openrouter",
            baseUrl="https://openrouter.ai/api/v1",
            reasoning=true,
            input=["text"],
            cost=Dict("input"=>0.39999999999999997, "output"=>4, "cacheRead"=>0, "cacheWrite"=>0),
            contextWindow=1000000,
            maxTokens=32768,
            headers=nothing
        ),
        "nvidia/nemotron-nano-9b-v2:free" => Model(
            id="nvidia/nemotron-nano-9b-v2:free",
            name="NVIDIA: Nemotron Nano 9B V2 (free)",
            api="openai-completions",
            provider="openrouter",
            baseUrl="https://openrouter.ai/api/v1",
            reasoning=true,
            input=["text"],
            cost=Dict("input"=>0, "output"=>0, "cacheRead"=>0, "cacheWrite"=>0),
            contextWindow=128000,
            maxTokens=4096,
            headers=nothing
        ),
        "nvidia/nemotron-nano-9b-v2" => Model(
            id="nvidia/nemotron-nano-9b-v2",
            name="NVIDIA: Nemotron Nano 9B V2",
            api="openai-completions",
            provider="openrouter",
            baseUrl="https://openrouter.ai/api/v1",
            reasoning=true,
            input=["text"],
            cost=Dict("input"=>0.04, "output"=>0.16, "cacheRead"=>0, "cacheWrite"=>0),
            contextWindow=131072,
            maxTokens=4096,
            headers=nothing
        ),
        "moonshotai/kimi-k2-0905" => Model(
            id="moonshotai/kimi-k2-0905",
            name="MoonshotAI: Kimi K2 0905",
            api="openai-completions",
            provider="openrouter",
            baseUrl="https://openrouter.ai/api/v1",
            reasoning=false,
            input=["text"],
            cost=Dict("input"=>0.39, "output"=>1.9, "cacheRead"=>0, "cacheWrite"=>0),
            contextWindow=262144,
            maxTokens=262144,
            headers=nothing
        ),
        "moonshotai/kimi-k2-0905:exacto" => Model(
            id="moonshotai/kimi-k2-0905:exacto",
            name="MoonshotAI: Kimi K2 0905 (exacto)",
            api="openai-completions",
            provider="openrouter",
            baseUrl="https://openrouter.ai/api/v1",
            reasoning=false,
            input=["text"],
            cost=Dict("input"=>0.6, "output"=>2.5, "cacheRead"=>0, "cacheWrite"=>0),
            contextWindow=262144,
            maxTokens=4096,
            headers=nothing
        ),
        "deepcogito/cogito-v2-preview-llama-70b" => Model(
            id="deepcogito/cogito-v2-preview-llama-70b",
            name="Deep Cogito: Cogito V2 Preview Llama 70B",
            api="openai-completions",
            provider="openrouter",
            baseUrl="https://openrouter.ai/api/v1",
            reasoning=true,
            input=["text"],
            cost=Dict("input"=>0.88, "output"=>0.88, "cacheRead"=>0, "cacheWrite"=>0),
            contextWindow=32768,
            maxTokens=4096,
            headers=nothing
        ),
        "deepcogito/cogito-v2-preview-llama-109b-moe" => Model(
            id="deepcogito/cogito-v2-preview-llama-109b-moe",
            name="Cogito V2 Preview Llama 109B",
            api="openai-completions",
            provider="openrouter",
            baseUrl="https://openrouter.ai/api/v1",
            reasoning=true,
            input=["text", "image"],
            cost=Dict("input"=>0.18, "output"=>0.59, "cacheRead"=>0, "cacheWrite"=>0),
            contextWindow=32767,
            maxTokens=4096,
            headers=nothing
        ),
        "stepfun-ai/step3" => Model(
            id="stepfun-ai/step3",
            name="StepFun: Step3",
            api="openai-completions",
            provider="openrouter",
            baseUrl="https://openrouter.ai/api/v1",
            reasoning=true,
            input=["text", "image"],
            cost=Dict("input"=>0.5700000000000001, "output"=>1.42, "cacheRead"=>0, "cacheWrite"=>0),
            contextWindow=65536,
            maxTokens=65536,
            headers=nothing
        ),
        "qwen/qwen3-30b-a3b-thinking-2507" => Model(
            id="qwen/qwen3-30b-a3b-thinking-2507",
            name="Qwen: Qwen3 30B A3B Thinking 2507",
            api="openai-completions",
            provider="openrouter",
            baseUrl="https://openrouter.ai/api/v1",
            reasoning=true,
            input=["text"],
            cost=Dict("input"=>0.051, "output"=>0.33999999999999997, "cacheRead"=>0, "cacheWrite"=>0),
            contextWindow=32768,
            maxTokens=4096,
            headers=nothing
        ),
        "x-ai/grok-code-fast-1" => Model(
            id="x-ai/grok-code-fast-1",
            name="xAI: Grok Code Fast 1",
            api="openai-completions",
            provider="openrouter",
            baseUrl="https://openrouter.ai/api/v1",
            reasoning=true,
            input=["text"],
            cost=Dict("input"=>0.19999999999999998, "output"=>1.5, "cacheRead"=>0.02, "cacheWrite"=>0),
            contextWindow=256000,
            maxTokens=10000,
            headers=nothing
        ),
        "nousresearch/hermes-4-70b" => Model(
            id="nousresearch/hermes-4-70b",
            name="Nous: Hermes 4 70B",
            api="openai-completions",
            provider="openrouter",
            baseUrl="https://openrouter.ai/api/v1",
            reasoning=true,
            input=["text"],
            cost=Dict("input"=>0.11, "output"=>0.38, "cacheRead"=>0, "cacheWrite"=>0),
            contextWindow=131072,
            maxTokens=131072,
            headers=nothing
        ),
        "nousresearch/hermes-4-405b" => Model(
            id="nousresearch/hermes-4-405b",
            name="Nous: Hermes 4 405B",
            api="openai-completions",
            provider="openrouter",
            baseUrl="https://openrouter.ai/api/v1",
            reasoning=true,
            input=["text"],
            cost=Dict("input"=>0.3, "output"=>1.2, "cacheRead"=>0, "cacheWrite"=>0),
            contextWindow=131072,
            maxTokens=131072,
            headers=nothing
        ),
        "deepseek/deepseek-chat-v3.1" => Model(
            id="deepseek/deepseek-chat-v3.1",
            name="DeepSeek: DeepSeek V3.1",
            api="openai-completions",
            provider="openrouter",
            baseUrl="https://openrouter.ai/api/v1",
            reasoning=true,
            input=["text"],
            cost=Dict("input"=>0.19999999999999998, "output"=>0.7999999999999999, "cacheRead"=>0, "cacheWrite"=>0),
            contextWindow=163840,
            maxTokens=163840,
            headers=nothing
        ),
        "openai/gpt-4o-audio-preview" => Model(
            id="openai/gpt-4o-audio-preview",
            name="OpenAI: GPT-4o Audio",
            api="openai-completions",
            provider="openrouter",
            baseUrl="https://openrouter.ai/api/v1",
            reasoning=false,
            input=["text"],
            cost=Dict("input"=>2.5, "output"=>10, "cacheRead"=>0, "cacheWrite"=>0),
            contextWindow=128000,
            maxTokens=16384,
            headers=nothing
        ),
        "mistralai/mistral-medium-3.1" => Model(
            id="mistralai/mistral-medium-3.1",
            name="Mistral: Mistral Medium 3.1",
            api="openai-completions",
            provider="openrouter",
            baseUrl="https://openrouter.ai/api/v1",
            reasoning=false,
            input=["text", "image"],
            cost=Dict("input"=>0.39999999999999997, "output"=>2, "cacheRead"=>0, "cacheWrite"=>0),
            contextWindow=131072,
            maxTokens=4096,
            headers=nothing
        ),
        "baidu/ernie-4.5-21b-a3b" => Model(
            id="baidu/ernie-4.5-21b-a3b",
            name="Baidu: ERNIE 4.5 21B A3B",
            api="openai-completions",
            provider="openrouter",
            baseUrl="https://openrouter.ai/api/v1",
            reasoning=false,
            input=["text"],
            cost=Dict("input"=>0.056, "output"=>0.224, "cacheRead"=>0, "cacheWrite"=>0),
            contextWindow=120000,
            maxTokens=8000,
            headers=nothing
        ),
        "baidu/ernie-4.5-vl-28b-a3b" => Model(
            id="baidu/ernie-4.5-vl-28b-a3b",
            name="Baidu: ERNIE 4.5 VL 28B A3B",
            api="openai-completions",
            provider="openrouter",
            baseUrl="https://openrouter.ai/api/v1",
            reasoning=true,
            input=["text", "image"],
            cost=Dict("input"=>0.112, "output"=>0.448, "cacheRead"=>0, "cacheWrite"=>0),
            contextWindow=30000,
            maxTokens=8000,
            headers=nothing
        ),
        "z-ai/glm-4.5v" => Model(
            id="z-ai/glm-4.5v",
            name="Z.AI: GLM 4.5V",
            api="openai-completions",
            provider="openrouter",
            baseUrl="https://openrouter.ai/api/v1",
            reasoning=true,
            input=["text", "image"],
            cost=Dict("input"=>0.48, "output"=>1.44, "cacheRead"=>0.088, "cacheWrite"=>0),
            contextWindow=65536,
            maxTokens=16384,
            headers=nothing
        ),
        "ai21/jamba-mini-1.7" => Model(
            id="ai21/jamba-mini-1.7",
            name="AI21: Jamba Mini 1.7",
            api="openai-completions",
            provider="openrouter",
            baseUrl="https://openrouter.ai/api/v1",
            reasoning=false,
            input=["text"],
            cost=Dict("input"=>0.19999999999999998, "output"=>0.39999999999999997, "cacheRead"=>0, "cacheWrite"=>0),
            contextWindow=256000,
            maxTokens=4096,
            headers=nothing
        ),
        "ai21/jamba-large-1.7" => Model(
            id="ai21/jamba-large-1.7",
            name="AI21: Jamba Large 1.7",
            api="openai-completions",
            provider="openrouter",
            baseUrl="https://openrouter.ai/api/v1",
            reasoning=false,
            input=["text"],
            cost=Dict("input"=>2, "output"=>8, "cacheRead"=>0, "cacheWrite"=>0),
            contextWindow=256000,
            maxTokens=4096,
            headers=nothing
        ),
        "openai/gpt-5" => Model(
            id="openai/gpt-5",
            name="OpenAI: GPT-5",
            api="openai-completions",
            provider="openrouter",
            baseUrl="https://openrouter.ai/api/v1",
            reasoning=true,
            input=["text", "image"],
            cost=Dict("input"=>1.25, "output"=>10, "cacheRead"=>0.125, "cacheWrite"=>0),
            contextWindow=400000,
            maxTokens=128000,
            headers=nothing
        ),
        "openai/gpt-5-mini" => Model(
            id="openai/gpt-5-mini",
            name="OpenAI: GPT-5 Mini",
            api="openai-completions",
            provider="openrouter",
            baseUrl="https://openrouter.ai/api/v1",
            reasoning=true,
            input=["text", "image"],
            cost=Dict("input"=>0.25, "output"=>2, "cacheRead"=>0.024999999999999998, "cacheWrite"=>0),
            contextWindow=400000,
            maxTokens=128000,
            headers=nothing
        ),
        "openai/gpt-5-nano" => Model(
            id="openai/gpt-5-nano",
            name="OpenAI: GPT-5 Nano",
            api="openai-completions",
            provider="openrouter",
            baseUrl="https://openrouter.ai/api/v1",
            reasoning=true,
            input=["text", "image"],
            cost=Dict("input"=>0.049999999999999996, "output"=>0.39999999999999997, "cacheRead"=>0.005, "cacheWrite"=>0),
            contextWindow=400000,
            maxTokens=128000,
            headers=nothing
        ),
        "openai/gpt-oss-120b:exacto" => Model(
            id="openai/gpt-oss-120b:exacto",
            name="OpenAI: gpt-oss-120b (exacto)",
            api="openai-completions",
            provider="openrouter",
            baseUrl="https://openrouter.ai/api/v1",
            reasoning=true,
            input=["text"],
            cost=Dict("input"=>0.04, "output"=>0.19999999999999998, "cacheRead"=>0, "cacheWrite"=>0),
            contextWindow=131072,
            maxTokens=32768,
            headers=nothing
        ),
        "openai/gpt-oss-120b" => Model(
            id="openai/gpt-oss-120b",
            name="OpenAI: gpt-oss-120b",
            api="openai-completions",
            provider="openrouter",
            baseUrl="https://openrouter.ai/api/v1",
            reasoning=true,
            input=["text"],
            cost=Dict("input"=>0.04, "output"=>0.19999999999999998, "cacheRead"=>0, "cacheWrite"=>0),
            contextWindow=131072,
            maxTokens=32768,
            headers=nothing
        ),
        "openai/gpt-oss-20b:free" => Model(
            id="openai/gpt-oss-20b:free",
            name="OpenAI: gpt-oss-20b (free)",
            api="openai-completions",
            provider="openrouter",
            baseUrl="https://openrouter.ai/api/v1",
            reasoning=true,
            input=["text"],
            cost=Dict("input"=>0, "output"=>0, "cacheRead"=>0, "cacheWrite"=>0),
            contextWindow=131072,
            maxTokens=131072,
            headers=nothing
        ),
        "openai/gpt-oss-20b" => Model(
            id="openai/gpt-oss-20b",
            name="OpenAI: gpt-oss-20b",
            api="openai-completions",
            provider="openrouter",
            baseUrl="https://openrouter.ai/api/v1",
            reasoning=true,
            input=["text"],
            cost=Dict("input"=>0.03, "output"=>0.14, "cacheRead"=>0, "cacheWrite"=>0),
            contextWindow=131072,
            maxTokens=4096,
            headers=nothing
        ),
        "anthropic/claude-opus-4.1" => Model(
            id="anthropic/claude-opus-4.1",
            name="Anthropic: Claude Opus 4.1",
            api="openai-completions",
            provider="openrouter",
            baseUrl="https://openrouter.ai/api/v1",
            reasoning=true,
            input=["text", "image"],
            cost=Dict("input"=>15, "output"=>75, "cacheRead"=>1.5, "cacheWrite"=>18.75),
            contextWindow=200000,
            maxTokens=32000,
            headers=nothing
        ),
        "mistralai/codestral-2508" => Model(
            id="mistralai/codestral-2508",
            name="Mistral: Codestral 2508",
            api="openai-completions",
            provider="openrouter",
            baseUrl="https://openrouter.ai/api/v1",
            reasoning=false,
            input=["text"],
            cost=Dict("input"=>0.3, "output"=>0.8999999999999999, "cacheRead"=>0, "cacheWrite"=>0),
            contextWindow=256000,
            maxTokens=4096,
            headers=nothing
        ),
        "qwen/qwen3-coder-30b-a3b-instruct" => Model(
            id="qwen/qwen3-coder-30b-a3b-instruct",
            name="Qwen: Qwen3 Coder 30B A3B Instruct",
            api="openai-completions",
            provider="openrouter",
            baseUrl="https://openrouter.ai/api/v1",
            reasoning=false,
            input=["text"],
            cost=Dict("input"=>0.06, "output"=>0.25, "cacheRead"=>0, "cacheWrite"=>0),
            contextWindow=262144,
            maxTokens=262144,
            headers=nothing
        ),
        "qwen/qwen3-30b-a3b-instruct-2507" => Model(
            id="qwen/qwen3-30b-a3b-instruct-2507",
            name="Qwen: Qwen3 30B A3B Instruct 2507",
            api="openai-completions",
            provider="openrouter",
            baseUrl="https://openrouter.ai/api/v1",
            reasoning=false,
            input=["text"],
            cost=Dict("input"=>0.08, "output"=>0.33, "cacheRead"=>0, "cacheWrite"=>0),
            contextWindow=262144,
            maxTokens=262144,
            headers=nothing
        ),
        "z-ai/glm-4.5" => Model(
            id="z-ai/glm-4.5",
            name="Z.AI: GLM 4.5",
            api="openai-completions",
            provider="openrouter",
            baseUrl="https://openrouter.ai/api/v1",
            reasoning=true,
            input=["text"],
            cost=Dict("input"=>0.35, "output"=>1.55, "cacheRead"=>0, "cacheWrite"=>0),
            contextWindow=131072,
            maxTokens=131072,
            headers=nothing
        ),
        "z-ai/glm-4.5-air:free" => Model(
            id="z-ai/glm-4.5-air:free",
            name="Z.AI: GLM 4.5 Air (free)",
            api="openai-completions",
            provider="openrouter",
            baseUrl="https://openrouter.ai/api/v1",
            reasoning=true,
            input=["text"],
            cost=Dict("input"=>0, "output"=>0, "cacheRead"=>0, "cacheWrite"=>0),
            contextWindow=131072,
            maxTokens=131072,
            headers=nothing
        ),
        "z-ai/glm-4.5-air" => Model(
            id="z-ai/glm-4.5-air",
            name="Z.AI: GLM 4.5 Air",
            api="openai-completions",
            provider="openrouter",
            baseUrl="https://openrouter.ai/api/v1",
            reasoning=true,
            input=["text"],
            cost=Dict("input"=>0.10400000000000001, "output"=>0.6799999999999999, "cacheRead"=>0, "cacheWrite"=>0),
            contextWindow=131072,
            maxTokens=98304,
            headers=nothing
        ),
        "qwen/qwen3-235b-a22b-thinking-2507" => Model(
            id="qwen/qwen3-235b-a22b-thinking-2507",
            name="Qwen: Qwen3 235B A22B Thinking 2507",
            api="openai-completions",
            provider="openrouter",
            baseUrl="https://openrouter.ai/api/v1",
            reasoning=true,
            input=["text"],
            cost=Dict("input"=>0.11, "output"=>0.6, "cacheRead"=>0, "cacheWrite"=>0),
            contextWindow=262144,
            maxTokens=262144,
            headers=nothing
        ),
        "z-ai/glm-4-32b" => Model(
            id="z-ai/glm-4-32b",
            name="Z.AI: GLM 4 32B ",
            api="openai-completions",
            provider="openrouter",
            baseUrl="https://openrouter.ai/api/v1",
            reasoning=false,
            input=["text"],
            cost=Dict("input"=>0.09999999999999999, "output"=>0.09999999999999999, "cacheRead"=>0, "cacheWrite"=>0),
            contextWindow=128000,
            maxTokens=4096,
            headers=nothing
        ),
        "qwen/qwen3-coder:free" => Model(
            id="qwen/qwen3-coder:free",
            name="Qwen: Qwen3 Coder 480B A35B (free)",
            api="openai-completions",
            provider="openrouter",
            baseUrl="https://openrouter.ai/api/v1",
            reasoning=false,
            input=["text"],
            cost=Dict("input"=>0, "output"=>0, "cacheRead"=>0, "cacheWrite"=>0),
            contextWindow=262000,
            maxTokens=262000,
            headers=nothing
        ),
        "qwen/qwen3-coder" => Model(
            id="qwen/qwen3-coder",
            name="Qwen: Qwen3 Coder 480B A35B",
            api="openai-completions",
            provider="openrouter",
            baseUrl="https://openrouter.ai/api/v1",
            reasoning=true,
            input=["text"],
            cost=Dict("input"=>0.22, "output"=>0.95, "cacheRead"=>0, "cacheWrite"=>0),
            contextWindow=262144,
            maxTokens=262144,
            headers=nothing
        ),
        "qwen/qwen3-coder:exacto" => Model(
            id="qwen/qwen3-coder:exacto",
            name="Qwen: Qwen3 Coder 480B A35B (exacto)",
            api="openai-completions",
            provider="openrouter",
            baseUrl="https://openrouter.ai/api/v1",
            reasoning=true,
            input=["text"],
            cost=Dict("input"=>0.38, "output"=>1.53, "cacheRead"=>0, "cacheWrite"=>0),
            contextWindow=262144,
            maxTokens=262144,
            headers=nothing
        ),
        "google/gemini-2.5-flash-lite" => Model(
            id="google/gemini-2.5-flash-lite",
            name="Google: Gemini 2.5 Flash Lite",
            api="openai-completions",
            provider="openrouter",
            baseUrl="https://openrouter.ai/api/v1",
            reasoning=true,
            input=["text", "image"],
            cost=Dict("input"=>0.09999999999999999, "output"=>0.39999999999999997, "cacheRead"=>0.01, "cacheWrite"=>0.18330000000000002),
            contextWindow=1048576,
            maxTokens=65535,
            headers=nothing
        ),
        "qwen/qwen3-235b-a22b-2507" => Model(
            id="qwen/qwen3-235b-a22b-2507",
            name="Qwen: Qwen3 235B A22B Instruct 2507",
            api="openai-completions",
            provider="openrouter",
            baseUrl="https://openrouter.ai/api/v1",
            reasoning=true,
            input=["text"],
            cost=Dict("input"=>0.072, "output"=>0.464, "cacheRead"=>0, "cacheWrite"=>0),
            contextWindow=131072,
            maxTokens=16384,
            headers=nothing
        ),
        "moonshotai/kimi-k2" => Model(
            id="moonshotai/kimi-k2",
            name="MoonshotAI: Kimi K2 0711",
            api="openai-completions",
            provider="openrouter",
            baseUrl="https://openrouter.ai/api/v1",
            reasoning=false,
            input=["text"],
            cost=Dict("input"=>0.456, "output"=>1.8399999999999999, "cacheRead"=>0, "cacheWrite"=>0),
            contextWindow=131072,
            maxTokens=131072,
            headers=nothing
        ),
        "mistralai/devstral-medium" => Model(
            id="mistralai/devstral-medium",
            name="Mistral: Devstral Medium",
            api="openai-completions",
            provider="openrouter",
            baseUrl="https://openrouter.ai/api/v1",
            reasoning=false,
            input=["text"],
            cost=Dict("input"=>0.39999999999999997, "output"=>2, "cacheRead"=>0, "cacheWrite"=>0),
            contextWindow=131072,
            maxTokens=4096,
            headers=nothing
        ),
        "mistralai/devstral-small" => Model(
            id="mistralai/devstral-small",
            name="Mistral: Devstral Small 1.1",
            api="openai-completions",
            provider="openrouter",
            baseUrl="https://openrouter.ai/api/v1",
            reasoning=false,
            input=["text"],
            cost=Dict("input"=>0.07, "output"=>0.28, "cacheRead"=>0, "cacheWrite"=>0),
            contextWindow=128000,
            maxTokens=4096,
            headers=nothing
        ),
        "x-ai/grok-4" => Model(
            id="x-ai/grok-4",
            name="xAI: Grok 4",
            api="openai-completions",
            provider="openrouter",
            baseUrl="https://openrouter.ai/api/v1",
            reasoning=true,
            input=["text", "image"],
            cost=Dict("input"=>3, "output"=>15, "cacheRead"=>0.75, "cacheWrite"=>0),
            contextWindow=256000,
            maxTokens=4096,
            headers=nothing
        ),
        "tngtech/deepseek-r1t2-chimera" => Model(
            id="tngtech/deepseek-r1t2-chimera",
            name="TNG: DeepSeek R1T2 Chimera",
            api="openai-completions",
            provider="openrouter",
            baseUrl="https://openrouter.ai/api/v1",
            reasoning=true,
            input=["text"],
            cost=Dict("input"=>0.3, "output"=>1.2, "cacheRead"=>0, "cacheWrite"=>0),
            contextWindow=163840,
            maxTokens=163840,
            headers=nothing
        ),
        "inception/mercury" => Model(
            id="inception/mercury",
            name="Inception: Mercury",
            api="openai-completions",
            provider="openrouter",
            baseUrl="https://openrouter.ai/api/v1",
            reasoning=false,
            input=["text"],
            cost=Dict("input"=>0.25, "output"=>1, "cacheRead"=>0, "cacheWrite"=>0),
            contextWindow=128000,
            maxTokens=16384,
            headers=nothing
        ),
        "mistralai/mistral-small-3.2-24b-instruct" => Model(
            id="mistralai/mistral-small-3.2-24b-instruct",
            name="Mistral: Mistral Small 3.2 24B",
            api="openai-completions",
            provider="openrouter",
            baseUrl="https://openrouter.ai/api/v1",
            reasoning=false,
            input=["text", "image"],
            cost=Dict("input"=>0.06, "output"=>0.18, "cacheRead"=>0, "cacheWrite"=>0),
            contextWindow=131072,
            maxTokens=131072,
            headers=nothing
        ),
        "minimax/minimax-m1" => Model(
            id="minimax/minimax-m1",
            name="MiniMax: MiniMax M1",
            api="openai-completions",
            provider="openrouter",
            baseUrl="https://openrouter.ai/api/v1",
            reasoning=true,
            input=["text"],
            cost=Dict("input"=>0.39999999999999997, "output"=>2.2, "cacheRead"=>0, "cacheWrite"=>0),
            contextWindow=1000000,
            maxTokens=40000,
            headers=nothing
        ),
        "google/gemini-2.5-flash" => Model(
            id="google/gemini-2.5-flash",
            name="Google: Gemini 2.5 Flash",
            api="openai-completions",
            provider="openrouter",
            baseUrl="https://openrouter.ai/api/v1",
            reasoning=true,
            input=["text", "image"],
            cost=Dict("input"=>0.3, "output"=>2.5, "cacheRead"=>0.03, "cacheWrite"=>0.3833),
            contextWindow=1048576,
            maxTokens=65535,
            headers=nothing
        ),
        "google/gemini-2.5-pro" => Model(
            id="google/gemini-2.5-pro",
            name="Google: Gemini 2.5 Pro",
            api="openai-completions",
            provider="openrouter",
            baseUrl="https://openrouter.ai/api/v1",
            reasoning=true,
            input=["text", "image"],
            cost=Dict("input"=>1.25, "output"=>10, "cacheRead"=>0.125, "cacheWrite"=>1.625),
            contextWindow=1048576,
            maxTokens=65536,
            headers=nothing
        ),
        "openai/o3-pro" => Model(
            id="openai/o3-pro",
            name="OpenAI: o3 Pro",
            api="openai-completions",
            provider="openrouter",
            baseUrl="https://openrouter.ai/api/v1",
            reasoning=true,
            input=["text", "image"],
            cost=Dict("input"=>20, "output"=>80, "cacheRead"=>0, "cacheWrite"=>0),
            contextWindow=200000,
            maxTokens=100000,
            headers=nothing
        ),
        "x-ai/grok-3-mini" => Model(
            id="x-ai/grok-3-mini",
            name="xAI: Grok 3 Mini",
            api="openai-completions",
            provider="openrouter",
            baseUrl="https://openrouter.ai/api/v1",
            reasoning=true,
            input=["text"],
            cost=Dict("input"=>0.3, "output"=>0.5, "cacheRead"=>0.075, "cacheWrite"=>0),
            contextWindow=131072,
            maxTokens=4096,
            headers=nothing
        ),
        "x-ai/grok-3" => Model(
            id="x-ai/grok-3",
            name="xAI: Grok 3",
            api="openai-completions",
            provider="openrouter",
            baseUrl="https://openrouter.ai/api/v1",
            reasoning=false,
            input=["text"],
            cost=Dict("input"=>3, "output"=>15, "cacheRead"=>0.75, "cacheWrite"=>0),
            contextWindow=131072,
            maxTokens=4096,
            headers=nothing
        ),
        "mistralai/magistral-small-2506" => Model(
            id="mistralai/magistral-small-2506",
            name="Mistral: Magistral Small 2506",
            api="openai-completions",
            provider="openrouter",
            baseUrl="https://openrouter.ai/api/v1",
            reasoning=true,
            input=["text"],
            cost=Dict("input"=>0.5, "output"=>1.5, "cacheRead"=>0, "cacheWrite"=>0),
            contextWindow=40000,
            maxTokens=40000,
            headers=nothing
        ),
        "mistralai/magistral-medium-2506:thinking" => Model(
            id="mistralai/magistral-medium-2506:thinking",
            name="Mistral: Magistral Medium 2506 (thinking)",
            api="openai-completions",
            provider="openrouter",
            baseUrl="https://openrouter.ai/api/v1",
            reasoning=true,
            input=["text"],
            cost=Dict("input"=>2, "output"=>5, "cacheRead"=>0, "cacheWrite"=>0),
            contextWindow=40960,
            maxTokens=40000,
            headers=nothing
        ),
        "mistralai/magistral-medium-2506" => Model(
            id="mistralai/magistral-medium-2506",
            name="Mistral: Magistral Medium 2506",
            api="openai-completions",
            provider="openrouter",
            baseUrl="https://openrouter.ai/api/v1",
            reasoning=true,
            input=["text"],
            cost=Dict("input"=>2, "output"=>5, "cacheRead"=>0, "cacheWrite"=>0),
            contextWindow=40960,
            maxTokens=40000,
            headers=nothing
        ),
        "google/gemini-2.5-pro-preview" => Model(
            id="google/gemini-2.5-pro-preview",
            name="Google: Gemini 2.5 Pro Preview 06-05",
            api="openai-completions",
            provider="openrouter",
            baseUrl="https://openrouter.ai/api/v1",
            reasoning=true,
            input=["text", "image"],
            cost=Dict("input"=>1.25, "output"=>10, "cacheRead"=>0.31, "cacheWrite"=>1.625),
            contextWindow=1048576,
            maxTokens=65536,
            headers=nothing
        ),
        "deepseek/deepseek-r1-0528" => Model(
            id="deepseek/deepseek-r1-0528",
            name="DeepSeek: R1 0528",
            api="openai-completions",
            provider="openrouter",
            baseUrl="https://openrouter.ai/api/v1",
            reasoning=true,
            input=["text"],
            cost=Dict("input"=>0.19999999999999998, "output"=>4.5, "cacheRead"=>0, "cacheWrite"=>0),
            contextWindow=163840,
            maxTokens=163840,
            headers=nothing
        ),
        "anthropic/claude-opus-4" => Model(
            id="anthropic/claude-opus-4",
            name="Anthropic: Claude Opus 4",
            api="openai-completions",
            provider="openrouter",
            baseUrl="https://openrouter.ai/api/v1",
            reasoning=true,
            input=["text", "image"],
            cost=Dict("input"=>15, "output"=>75, "cacheRead"=>1.5, "cacheWrite"=>18.75),
            contextWindow=200000,
            maxTokens=32000,
            headers=nothing
        ),
        "anthropic/claude-sonnet-4" => Model(
            id="anthropic/claude-sonnet-4",
            name="Anthropic: Claude Sonnet 4",
            api="openai-completions",
            provider="openrouter",
            baseUrl="https://openrouter.ai/api/v1",
            reasoning=true,
            input=["text", "image"],
            cost=Dict("input"=>3, "output"=>15, "cacheRead"=>0.3, "cacheWrite"=>3.75),
            contextWindow=1000000,
            maxTokens=64000,
            headers=nothing
        ),
        "mistralai/devstral-small-2505" => Model(
            id="mistralai/devstral-small-2505",
            name="Mistral: Devstral Small 2505",
            api="openai-completions",
            provider="openrouter",
            baseUrl="https://openrouter.ai/api/v1",
            reasoning=false,
            input=["text"],
            cost=Dict("input"=>0.06, "output"=>0.12, "cacheRead"=>0, "cacheWrite"=>0),
            contextWindow=128000,
            maxTokens=4096,
            headers=nothing
        ),
        "openai/codex-mini" => Model(
            id="openai/codex-mini",
            name="OpenAI: Codex Mini",
            api="openai-completions",
            provider="openrouter",
            baseUrl="https://openrouter.ai/api/v1",
            reasoning=true,
            input=["text", "image"],
            cost=Dict("input"=>1.5, "output"=>6, "cacheRead"=>0.375, "cacheWrite"=>0),
            contextWindow=200000,
            maxTokens=100000,
            headers=nothing
        ),
        "nousresearch/deephermes-3-mistral-24b-preview" => Model(
            id="nousresearch/deephermes-3-mistral-24b-preview",
            name="Nous: DeepHermes 3 Mistral 24B Preview",
            api="openai-completions",
            provider="openrouter",
            baseUrl="https://openrouter.ai/api/v1",
            reasoning=true,
            input=["text"],
            cost=Dict("input"=>0.049999999999999996, "output"=>0.19999999999999998, "cacheRead"=>0, "cacheWrite"=>0),
            contextWindow=32768,
            maxTokens=32768,
            headers=nothing
        ),
        "mistralai/mistral-medium-3" => Model(
            id="mistralai/mistral-medium-3",
            name="Mistral: Mistral Medium 3",
            api="openai-completions",
            provider="openrouter",
            baseUrl="https://openrouter.ai/api/v1",
            reasoning=false,
            input=["text", "image"],
            cost=Dict("input"=>0.39999999999999997, "output"=>2, "cacheRead"=>0, "cacheWrite"=>0),
            contextWindow=131072,
            maxTokens=4096,
            headers=nothing
        ),
        "google/gemini-2.5-pro-preview-05-06" => Model(
            id="google/gemini-2.5-pro-preview-05-06",
            name="Google: Gemini 2.5 Pro Preview 05-06",
            api="openai-completions",
            provider="openrouter",
            baseUrl="https://openrouter.ai/api/v1",
            reasoning=true,
            input=["text", "image"],
            cost=Dict("input"=>1.25, "output"=>10, "cacheRead"=>0.31, "cacheWrite"=>1.625),
            contextWindow=1048576,
            maxTokens=65535,
            headers=nothing
        ),
        "arcee-ai/virtuoso-large" => Model(
            id="arcee-ai/virtuoso-large",
            name="Arcee AI: Virtuoso Large",
            api="openai-completions",
            provider="openrouter",
            baseUrl="https://openrouter.ai/api/v1",
            reasoning=false,
            input=["text"],
            cost=Dict("input"=>0.75, "output"=>1.2, "cacheRead"=>0, "cacheWrite"=>0),
            contextWindow=131072,
            maxTokens=64000,
            headers=nothing
        ),
        "inception/mercury-coder" => Model(
            id="inception/mercury-coder",
            name="Inception: Mercury Coder",
            api="openai-completions",
            provider="openrouter",
            baseUrl="https://openrouter.ai/api/v1",
            reasoning=false,
            input=["text"],
            cost=Dict("input"=>0.25, "output"=>1, "cacheRead"=>0, "cacheWrite"=>0),
            contextWindow=128000,
            maxTokens=16384,
            headers=nothing
        ),
        "qwen/qwen3-4b:free" => Model(
            id="qwen/qwen3-4b:free",
            name="Qwen: Qwen3 4B (free)",
            api="openai-completions",
            provider="openrouter",
            baseUrl="https://openrouter.ai/api/v1",
            reasoning=true,
            input=["text"],
            cost=Dict("input"=>0, "output"=>0, "cacheRead"=>0, "cacheWrite"=>0),
            contextWindow=40960,
            maxTokens=4096,
            headers=nothing
        ),
        "qwen/qwen3-30b-a3b" => Model(
            id="qwen/qwen3-30b-a3b",
            name="Qwen: Qwen3 30B A3B",
            api="openai-completions",
            provider="openrouter",
            baseUrl="https://openrouter.ai/api/v1",
            reasoning=true,
            input=["text"],
            cost=Dict("input"=>0.06, "output"=>0.22, "cacheRead"=>0, "cacheWrite"=>0),
            contextWindow=40960,
            maxTokens=40960,
            headers=nothing
        ),
        "qwen/qwen3-8b" => Model(
            id="qwen/qwen3-8b",
            name="Qwen: Qwen3 8B",
            api="openai-completions",
            provider="openrouter",
            baseUrl="https://openrouter.ai/api/v1",
            reasoning=true,
            input=["text"],
            cost=Dict("input"=>0.028, "output"=>0.1104, "cacheRead"=>0, "cacheWrite"=>0),
            contextWindow=128000,
            maxTokens=20000,
            headers=nothing
        ),
        "qwen/qwen3-14b" => Model(
            id="qwen/qwen3-14b",
            name="Qwen: Qwen3 14B",
            api="openai-completions",
            provider="openrouter",
            baseUrl="https://openrouter.ai/api/v1",
            reasoning=true,
            input=["text"],
            cost=Dict("input"=>0.049999999999999996, "output"=>0.22, "cacheRead"=>0, "cacheWrite"=>0),
            contextWindow=40960,
            maxTokens=40960,
            headers=nothing
        ),
        "qwen/qwen3-32b" => Model(
            id="qwen/qwen3-32b",
            name="Qwen: Qwen3 32B",
            api="openai-completions",
            provider="openrouter",
            baseUrl="https://openrouter.ai/api/v1",
            reasoning=true,
            input=["text"],
            cost=Dict("input"=>0.08, "output"=>0.24, "cacheRead"=>0, "cacheWrite"=>0),
            contextWindow=40960,
            maxTokens=40960,
            headers=nothing
        ),
        "qwen/qwen3-235b-a22b:free" => Model(
            id="qwen/qwen3-235b-a22b:free",
            name="Qwen: Qwen3 235B A22B (free)",
            api="openai-completions",
            provider="openrouter",
            baseUrl="https://openrouter.ai/api/v1",
            reasoning=true,
            input=["text"],
            cost=Dict("input"=>0, "output"=>0, "cacheRead"=>0, "cacheWrite"=>0),
            contextWindow=131072,
            maxTokens=4096,
            headers=nothing
        ),
        "qwen/qwen3-235b-a22b" => Model(
            id="qwen/qwen3-235b-a22b",
            name="Qwen: Qwen3 235B A22B",
            api="openai-completions",
            provider="openrouter",
            baseUrl="https://openrouter.ai/api/v1",
            reasoning=true,
            input=["text"],
            cost=Dict("input"=>0.18, "output"=>0.54, "cacheRead"=>0, "cacheWrite"=>0),
            contextWindow=40960,
            maxTokens=40960,
            headers=nothing
        ),
        "openai/o4-mini-high" => Model(
            id="openai/o4-mini-high",
            name="OpenAI: o4 Mini High",
            api="openai-completions",
            provider="openrouter",
            baseUrl="https://openrouter.ai/api/v1",
            reasoning=true,
            input=["text", "image"],
            cost=Dict("input"=>1.1, "output"=>4.4, "cacheRead"=>0.275, "cacheWrite"=>0),
            contextWindow=200000,
            maxTokens=100000,
            headers=nothing
        ),
        "openai/o3" => Model(
            id="openai/o3",
            name="OpenAI: o3",
            api="openai-completions",
            provider="openrouter",
            baseUrl="https://openrouter.ai/api/v1",
            reasoning=true,
            input=["text", "image"],
            cost=Dict("input"=>2, "output"=>8, "cacheRead"=>0.5, "cacheWrite"=>0),
            contextWindow=200000,
            maxTokens=100000,
            headers=nothing
        ),
        "openai/o4-mini" => Model(
            id="openai/o4-mini",
            name="OpenAI: o4 Mini",
            api="openai-completions",
            provider="openrouter",
            baseUrl="https://openrouter.ai/api/v1",
            reasoning=true,
            input=["text", "image"],
            cost=Dict("input"=>1.1, "output"=>4.4, "cacheRead"=>0.275, "cacheWrite"=>0),
            contextWindow=200000,
            maxTokens=100000,
            headers=nothing
        ),
        "openai/gpt-4.1" => Model(
            id="openai/gpt-4.1",
            name="OpenAI: GPT-4.1",
            api="openai-completions",
            provider="openrouter",
            baseUrl="https://openrouter.ai/api/v1",
            reasoning=false,
            input=["text", "image"],
            cost=Dict("input"=>2, "output"=>8, "cacheRead"=>0.5, "cacheWrite"=>0),
            contextWindow=1047576,
            maxTokens=32768,
            headers=nothing
        ),
        "openai/gpt-4.1-mini" => Model(
            id="openai/gpt-4.1-mini",
            name="OpenAI: GPT-4.1 Mini",
            api="openai-completions",
            provider="openrouter",
            baseUrl="https://openrouter.ai/api/v1",
            reasoning=false,
            input=["text", "image"],
            cost=Dict("input"=>0.39999999999999997, "output"=>1.5999999999999999, "cacheRead"=>0.09999999999999999, "cacheWrite"=>0),
            contextWindow=1047576,
            maxTokens=32768,
            headers=nothing
        ),
        "openai/gpt-4.1-nano" => Model(
            id="openai/gpt-4.1-nano",
            name="OpenAI: GPT-4.1 Nano",
            api="openai-completions",
            provider="openrouter",
            baseUrl="https://openrouter.ai/api/v1",
            reasoning=false,
            input=["text", "image"],
            cost=Dict("input"=>0.09999999999999999, "output"=>0.39999999999999997, "cacheRead"=>0.024999999999999998, "cacheWrite"=>0),
            contextWindow=1047576,
            maxTokens=32768,
            headers=nothing
        ),
        "x-ai/grok-3-mini-beta" => Model(
            id="x-ai/grok-3-mini-beta",
            name="xAI: Grok 3 Mini Beta",
            api="openai-completions",
            provider="openrouter",
            baseUrl="https://openrouter.ai/api/v1",
            reasoning=true,
            input=["text"],
            cost=Dict("input"=>0.3, "output"=>0.5, "cacheRead"=>0.075, "cacheWrite"=>0),
            contextWindow=131072,
            maxTokens=4096,
            headers=nothing
        ),
        "x-ai/grok-3-beta" => Model(
            id="x-ai/grok-3-beta",
            name="xAI: Grok 3 Beta",
            api="openai-completions",
            provider="openrouter",
            baseUrl="https://openrouter.ai/api/v1",
            reasoning=false,
            input=["text"],
            cost=Dict("input"=>3, "output"=>15, "cacheRead"=>0.75, "cacheWrite"=>0),
            contextWindow=131072,
            maxTokens=4096,
            headers=nothing
        ),
        "meta-llama/llama-4-maverick" => Model(
            id="meta-llama/llama-4-maverick",
            name="Meta: Llama 4 Maverick",
            api="openai-completions",
            provider="openrouter",
            baseUrl="https://openrouter.ai/api/v1",
            reasoning=false,
            input=["text", "image"],
            cost=Dict("input"=>0.136, "output"=>0.6799999999999999, "cacheRead"=>0, "cacheWrite"=>0),
            contextWindow=1048576,
            maxTokens=8192,
            headers=nothing
        ),
        "meta-llama/llama-4-scout" => Model(
            id="meta-llama/llama-4-scout",
            name="Meta: Llama 4 Scout",
            api="openai-completions",
            provider="openrouter",
            baseUrl="https://openrouter.ai/api/v1",
            reasoning=false,
            input=["text", "image"],
            cost=Dict("input"=>0.08, "output"=>0.3, "cacheRead"=>0, "cacheWrite"=>0),
            contextWindow=327680,
            maxTokens=16384,
            headers=nothing
        ),
        "deepseek/deepseek-chat-v3-0324" => Model(
            id="deepseek/deepseek-chat-v3-0324",
            name="DeepSeek: DeepSeek V3 0324",
            api="openai-completions",
            provider="openrouter",
            baseUrl="https://openrouter.ai/api/v1",
            reasoning=true,
            input=["text"],
            cost=Dict("input"=>0.19999999999999998, "output"=>0.88, "cacheRead"=>0.106, "cacheWrite"=>0),
            contextWindow=163840,
            maxTokens=4096,
            headers=nothing
        ),
        "mistralai/mistral-small-3.1-24b-instruct:free" => Model(
            id="mistralai/mistral-small-3.1-24b-instruct:free",
            name="Mistral: Mistral Small 3.1 24B (free)",
            api="openai-completions",
            provider="openrouter",
            baseUrl="https://openrouter.ai/api/v1",
            reasoning=false,
            input=["text", "image"],
            cost=Dict("input"=>0, "output"=>0, "cacheRead"=>0, "cacheWrite"=>0),
            contextWindow=128000,
            maxTokens=4096,
            headers=nothing
        ),
        "mistralai/mistral-small-3.1-24b-instruct" => Model(
            id="mistralai/mistral-small-3.1-24b-instruct",
            name="Mistral: Mistral Small 3.1 24B",
            api="openai-completions",
            provider="openrouter",
            baseUrl="https://openrouter.ai/api/v1",
            reasoning=false,
            input=["text", "image"],
            cost=Dict("input"=>0.03, "output"=>0.11, "cacheRead"=>0, "cacheWrite"=>0),
            contextWindow=131072,
            maxTokens=131072,
            headers=nothing
        ),
        "google/gemma-3-27b-it" => Model(
            id="google/gemma-3-27b-it",
            name="Google: Gemma 3 27B",
            api="openai-completions",
            provider="openrouter",
            baseUrl="https://openrouter.ai/api/v1",
            reasoning=false,
            input=["text", "image"],
            cost=Dict("input"=>0.07, "output"=>0.5, "cacheRead"=>0, "cacheWrite"=>0),
            contextWindow=131072,
            maxTokens=131072,
            headers=nothing
        ),
        "qwen/qwq-32b" => Model(
            id="qwen/qwq-32b",
            name="Qwen: QwQ 32B",
            api="openai-completions",
            provider="openrouter",
            baseUrl="https://openrouter.ai/api/v1",
            reasoning=true,
            input=["text"],
            cost=Dict("input"=>0.15, "output"=>0.39999999999999997, "cacheRead"=>0, "cacheWrite"=>0),
            contextWindow=32768,
            maxTokens=4096,
            headers=nothing
        ),
        "google/gemini-2.0-flash-lite-001" => Model(
            id="google/gemini-2.0-flash-lite-001",
            name="Google: Gemini 2.0 Flash Lite",
            api="openai-completions",
            provider="openrouter",
            baseUrl="https://openrouter.ai/api/v1",
            reasoning=false,
            input=["text", "image"],
            cost=Dict("input"=>0.075, "output"=>0.3, "cacheRead"=>0, "cacheWrite"=>0),
            contextWindow=1048576,
            maxTokens=8192,
            headers=nothing
        ),
        "anthropic/claude-3.7-sonnet:thinking" => Model(
            id="anthropic/claude-3.7-sonnet:thinking",
            name="Anthropic: Claude 3.7 Sonnet (thinking)",
            api="openai-completions",
            provider="openrouter",
            baseUrl="https://openrouter.ai/api/v1",
            reasoning=true,
            input=["text", "image"],
            cost=Dict("input"=>3, "output"=>15, "cacheRead"=>0.3, "cacheWrite"=>3.75),
            contextWindow=200000,
            maxTokens=64000,
            headers=nothing
        ),
        "anthropic/claude-3.7-sonnet" => Model(
            id="anthropic/claude-3.7-sonnet",
            name="Anthropic: Claude 3.7 Sonnet",
            api="openai-completions",
            provider="openrouter",
            baseUrl="https://openrouter.ai/api/v1",
            reasoning=true,
            input=["text", "image"],
            cost=Dict("input"=>3, "output"=>15, "cacheRead"=>0.3, "cacheWrite"=>3.75),
            contextWindow=200000,
            maxTokens=64000,
            headers=nothing
        ),
        "mistralai/mistral-saba" => Model(
            id="mistralai/mistral-saba",
            name="Mistral: Saba",
            api="openai-completions",
            provider="openrouter",
            baseUrl="https://openrouter.ai/api/v1",
            reasoning=false,
            input=["text"],
            cost=Dict("input"=>0.19999999999999998, "output"=>0.6, "cacheRead"=>0, "cacheWrite"=>0),
            contextWindow=32768,
            maxTokens=4096,
            headers=nothing
        ),
        "openai/o3-mini-high" => Model(
            id="openai/o3-mini-high",
            name="OpenAI: o3 Mini High",
            api="openai-completions",
            provider="openrouter",
            baseUrl="https://openrouter.ai/api/v1",
            reasoning=false,
            input=["text"],
            cost=Dict("input"=>1.1, "output"=>4.4, "cacheRead"=>0.55, "cacheWrite"=>0),
            contextWindow=200000,
            maxTokens=100000,
            headers=nothing
        ),
        "google/gemini-2.0-flash-001" => Model(
            id="google/gemini-2.0-flash-001",
            name="Google: Gemini 2.0 Flash",
            api="openai-completions",
            provider="openrouter",
            baseUrl="https://openrouter.ai/api/v1",
            reasoning=false,
            input=["text", "image"],
            cost=Dict("input"=>0.09999999999999999, "output"=>0.39999999999999997, "cacheRead"=>0.024999999999999998, "cacheWrite"=>0.18330000000000002),
            contextWindow=1048576,
            maxTokens=8192,
            headers=nothing
        ),
        "qwen/qwen-vl-max" => Model(
            id="qwen/qwen-vl-max",
            name="Qwen: Qwen VL Max",
            api="openai-completions",
            provider="openrouter",
            baseUrl="https://openrouter.ai/api/v1",
            reasoning=false,
            input=["text", "image"],
            cost=Dict("input"=>0.7999999999999999, "output"=>3.1999999999999997, "cacheRead"=>0, "cacheWrite"=>0),
            contextWindow=131072,
            maxTokens=8192,
            headers=nothing
        ),
        "qwen/qwen-turbo" => Model(
            id="qwen/qwen-turbo",
            name="Qwen: Qwen-Turbo",
            api="openai-completions",
            provider="openrouter",
            baseUrl="https://openrouter.ai/api/v1",
            reasoning=false,
            input=["text"],
            cost=Dict("input"=>0.049999999999999996, "output"=>0.19999999999999998, "cacheRead"=>0.02, "cacheWrite"=>0),
            contextWindow=1000000,
            maxTokens=8192,
            headers=nothing
        ),
        "qwen/qwen-plus" => Model(
            id="qwen/qwen-plus",
            name="Qwen: Qwen-Plus",
            api="openai-completions",
            provider="openrouter",
            baseUrl="https://openrouter.ai/api/v1",
            reasoning=false,
            input=["text"],
            cost=Dict("input"=>0.39999999999999997, "output"=>1.2, "cacheRead"=>0.16, "cacheWrite"=>0),
            contextWindow=131072,
            maxTokens=8192,
            headers=nothing
        ),
        "qwen/qwen-max" => Model(
            id="qwen/qwen-max",
            name="Qwen: Qwen-Max ",
            api="openai-completions",
            provider="openrouter",
            baseUrl="https://openrouter.ai/api/v1",
            reasoning=false,
            input=["text"],
            cost=Dict("input"=>1.5999999999999999, "output"=>6.3999999999999995, "cacheRead"=>0.64, "cacheWrite"=>0),
            contextWindow=32768,
            maxTokens=8192,
            headers=nothing
        ),
        "openai/o3-mini" => Model(
            id="openai/o3-mini",
            name="OpenAI: o3 Mini",
            api="openai-completions",
            provider="openrouter",
            baseUrl="https://openrouter.ai/api/v1",
            reasoning=false,
            input=["text"],
            cost=Dict("input"=>1.1, "output"=>4.4, "cacheRead"=>0.55, "cacheWrite"=>0),
            contextWindow=200000,
            maxTokens=100000,
            headers=nothing
        ),
        "mistralai/mistral-small-24b-instruct-2501" => Model(
            id="mistralai/mistral-small-24b-instruct-2501",
            name="Mistral: Mistral Small 3",
            api="openai-completions",
            provider="openrouter",
            baseUrl="https://openrouter.ai/api/v1",
            reasoning=false,
            input=["text"],
            cost=Dict("input"=>0.049999999999999996, "output"=>0.08, "cacheRead"=>0, "cacheWrite"=>0),
            contextWindow=32768,
            maxTokens=16384,
            headers=nothing
        ),
        "deepseek/deepseek-r1-distill-llama-70b" => Model(
            id="deepseek/deepseek-r1-distill-llama-70b",
            name="DeepSeek: R1 Distill Llama 70B",
            api="openai-completions",
            provider="openrouter",
            baseUrl="https://openrouter.ai/api/v1",
            reasoning=true,
            input=["text"],
            cost=Dict("input"=>0.03, "output"=>0.13, "cacheRead"=>0, "cacheWrite"=>0),
            contextWindow=131072,
            maxTokens=131072,
            headers=nothing
        ),
        "deepseek/deepseek-r1" => Model(
            id="deepseek/deepseek-r1",
            name="DeepSeek: R1",
            api="openai-completions",
            provider="openrouter",
            baseUrl="https://openrouter.ai/api/v1",
            reasoning=true,
            input=["text"],
            cost=Dict("input"=>0.3, "output"=>1.2, "cacheRead"=>0, "cacheWrite"=>0),
            contextWindow=163840,
            maxTokens=4096,
            headers=nothing
        ),
        "mistralai/codestral-2501" => Model(
            id="mistralai/codestral-2501",
            name="Mistral: Codestral 2501",
            api="openai-completions",
            provider="openrouter",
            baseUrl="https://openrouter.ai/api/v1",
            reasoning=false,
            input=["text"],
            cost=Dict("input"=>0.3, "output"=>0.8999999999999999, "cacheRead"=>0, "cacheWrite"=>0),
            contextWindow=256000,
            maxTokens=4096,
            headers=nothing
        ),
        "deepseek/deepseek-chat" => Model(
            id="deepseek/deepseek-chat",
            name="DeepSeek: DeepSeek V3",
            api="openai-completions",
            provider="openrouter",
            baseUrl="https://openrouter.ai/api/v1",
            reasoning=false,
            input=["text"],
            cost=Dict("input"=>0.3, "output"=>1.2, "cacheRead"=>0, "cacheWrite"=>0),
            contextWindow=163840,
            maxTokens=163840,
            headers=nothing
        ),
        "openai/o1" => Model(
            id="openai/o1",
            name="OpenAI: o1",
            api="openai-completions",
            provider="openrouter",
            baseUrl="https://openrouter.ai/api/v1",
            reasoning=false,
            input=["text", "image"],
            cost=Dict("input"=>15, "output"=>60, "cacheRead"=>7.5, "cacheWrite"=>0),
            contextWindow=200000,
            maxTokens=100000,
            headers=nothing
        ),
        "google/gemini-2.0-flash-exp:free" => Model(
            id="google/gemini-2.0-flash-exp:free",
            name="Google: Gemini 2.0 Flash Experimental (free)",
            api="openai-completions",
            provider="openrouter",
            baseUrl="https://openrouter.ai/api/v1",
            reasoning=false,
            input=["text", "image"],
            cost=Dict("input"=>0, "output"=>0, "cacheRead"=>0, "cacheWrite"=>0),
            contextWindow=1048576,
            maxTokens=8192,
            headers=nothing
        ),
        "meta-llama/llama-3.3-70b-instruct:free" => Model(
            id="meta-llama/llama-3.3-70b-instruct:free",
            name="Meta: Llama 3.3 70B Instruct (free)",
            api="openai-completions",
            provider="openrouter",
            baseUrl="https://openrouter.ai/api/v1",
            reasoning=false,
            input=["text"],
            cost=Dict("input"=>0, "output"=>0, "cacheRead"=>0, "cacheWrite"=>0),
            contextWindow=131072,
            maxTokens=4096,
            headers=nothing
        ),
        "meta-llama/llama-3.3-70b-instruct" => Model(
            id="meta-llama/llama-3.3-70b-instruct",
            name="Meta: Llama 3.3 70B Instruct",
            api="openai-completions",
            provider="openrouter",
            baseUrl="https://openrouter.ai/api/v1",
            reasoning=false,
            input=["text"],
            cost=Dict("input"=>0.10400000000000001, "output"=>0.312, "cacheRead"=>0, "cacheWrite"=>0),
            contextWindow=131072,
            maxTokens=120000,
            headers=nothing
        ),
        "amazon/nova-lite-v1" => Model(
            id="amazon/nova-lite-v1",
            name="Amazon: Nova Lite 1.0",
            api="openai-completions",
            provider="openrouter",
            baseUrl="https://openrouter.ai/api/v1",
            reasoning=false,
            input=["text", "image"],
            cost=Dict("input"=>0.06, "output"=>0.24, "cacheRead"=>0, "cacheWrite"=>0),
            contextWindow=300000,
            maxTokens=5120,
            headers=nothing
        ),
        "amazon/nova-micro-v1" => Model(
            id="amazon/nova-micro-v1",
            name="Amazon: Nova Micro 1.0",
            api="openai-completions",
            provider="openrouter",
            baseUrl="https://openrouter.ai/api/v1",
            reasoning=false,
            input=["text"],
            cost=Dict("input"=>0.035, "output"=>0.14, "cacheRead"=>0, "cacheWrite"=>0),
            contextWindow=128000,
            maxTokens=5120,
            headers=nothing
        ),
        "amazon/nova-pro-v1" => Model(
            id="amazon/nova-pro-v1",
            name="Amazon: Nova Pro 1.0",
            api="openai-completions",
            provider="openrouter",
            baseUrl="https://openrouter.ai/api/v1",
            reasoning=false,
            input=["text", "image"],
            cost=Dict("input"=>0.7999999999999999, "output"=>3.1999999999999997, "cacheRead"=>0, "cacheWrite"=>0),
            contextWindow=300000,
            maxTokens=5120,
            headers=nothing
        ),
        "openai/gpt-4o-2024-11-20" => Model(
            id="openai/gpt-4o-2024-11-20",
            name="OpenAI: GPT-4o (2024-11-20)",
            api="openai-completions",
            provider="openrouter",
            baseUrl="https://openrouter.ai/api/v1",
            reasoning=false,
            input=["text", "image"],
            cost=Dict("input"=>2.5, "output"=>10, "cacheRead"=>1.25, "cacheWrite"=>0),
            contextWindow=128000,
            maxTokens=16384,
            headers=nothing
        ),
        "mistralai/mistral-large-2411" => Model(
            id="mistralai/mistral-large-2411",
            name="Mistral Large 2411",
            api="openai-completions",
            provider="openrouter",
            baseUrl="https://openrouter.ai/api/v1",
            reasoning=false,
            input=["text"],
            cost=Dict("input"=>2, "output"=>6, "cacheRead"=>0, "cacheWrite"=>0),
            contextWindow=131072,
            maxTokens=4096,
            headers=nothing
        ),
        "mistralai/mistral-large-2407" => Model(
            id="mistralai/mistral-large-2407",
            name="Mistral Large 2407",
            api="openai-completions",
            provider="openrouter",
            baseUrl="https://openrouter.ai/api/v1",
            reasoning=false,
            input=["text"],
            cost=Dict("input"=>2, "output"=>6, "cacheRead"=>0, "cacheWrite"=>0),
            contextWindow=131072,
            maxTokens=4096,
            headers=nothing
        ),
        "mistralai/pixtral-large-2411" => Model(
            id="mistralai/pixtral-large-2411",
            name="Mistral: Pixtral Large 2411",
            api="openai-completions",
            provider="openrouter",
            baseUrl="https://openrouter.ai/api/v1",
            reasoning=false,
            input=["text", "image"],
            cost=Dict("input"=>2, "output"=>6, "cacheRead"=>0, "cacheWrite"=>0),
            contextWindow=131072,
            maxTokens=4096,
            headers=nothing
        ),
        "thedrummer/unslopnemo-12b" => Model(
            id="thedrummer/unslopnemo-12b",
            name="TheDrummer: UnslopNemo 12B",
            api="openai-completions",
            provider="openrouter",
            baseUrl="https://openrouter.ai/api/v1",
            reasoning=false,
            input=["text"],
            cost=Dict("input"=>0.39999999999999997, "output"=>0.39999999999999997, "cacheRead"=>0, "cacheWrite"=>0),
            contextWindow=32768,
            maxTokens=4096,
            headers=nothing
        ),
        "anthropic/claude-3.5-haiku-20241022" => Model(
            id="anthropic/claude-3.5-haiku-20241022",
            name="Anthropic: Claude 3.5 Haiku (2024-10-22)",
            api="openai-completions",
            provider="openrouter",
            baseUrl="https://openrouter.ai/api/v1",
            reasoning=false,
            input=["text", "image"],
            cost=Dict("input"=>0.7999999999999999, "output"=>4, "cacheRead"=>0.08, "cacheWrite"=>1),
            contextWindow=200000,
            maxTokens=8192,
            headers=nothing
        ),
        "anthropic/claude-3.5-haiku" => Model(
            id="anthropic/claude-3.5-haiku",
            name="Anthropic: Claude 3.5 Haiku",
            api="openai-completions",
            provider="openrouter",
            baseUrl="https://openrouter.ai/api/v1",
            reasoning=false,
            input=["text", "image"],
            cost=Dict("input"=>0.7999999999999999, "output"=>4, "cacheRead"=>0.08, "cacheWrite"=>1),
            contextWindow=200000,
            maxTokens=8192,
            headers=nothing
        ),
        "anthropic/claude-3.5-sonnet" => Model(
            id="anthropic/claude-3.5-sonnet",
            name="Anthropic: Claude 3.5 Sonnet",
            api="openai-completions",
            provider="openrouter",
            baseUrl="https://openrouter.ai/api/v1",
            reasoning=false,
            input=["text", "image"],
            cost=Dict("input"=>6, "output"=>30, "cacheRead"=>0, "cacheWrite"=>0),
            contextWindow=200000,
            maxTokens=8192,
            headers=nothing
        ),
        "mistralai/ministral-8b" => Model(
            id="mistralai/ministral-8b",
            name="Mistral: Ministral 8B",
            api="openai-completions",
            provider="openrouter",
            baseUrl="https://openrouter.ai/api/v1",
            reasoning=false,
            input=["text"],
            cost=Dict("input"=>0.09999999999999999, "output"=>0.09999999999999999, "cacheRead"=>0, "cacheWrite"=>0),
            contextWindow=131072,
            maxTokens=4096,
            headers=nothing
        ),
        "mistralai/ministral-3b" => Model(
            id="mistralai/ministral-3b",
            name="Mistral: Ministral 3B",
            api="openai-completions",
            provider="openrouter",
            baseUrl="https://openrouter.ai/api/v1",
            reasoning=false,
            input=["text"],
            cost=Dict("input"=>0.04, "output"=>0.04, "cacheRead"=>0, "cacheWrite"=>0),
            contextWindow=131072,
            maxTokens=4096,
            headers=nothing
        ),
        "nvidia/llama-3.1-nemotron-70b-instruct" => Model(
            id="nvidia/llama-3.1-nemotron-70b-instruct",
            name="NVIDIA: Llama 3.1 Nemotron 70B Instruct",
            api="openai-completions",
            provider="openrouter",
            baseUrl="https://openrouter.ai/api/v1",
            reasoning=false,
            input=["text"],
            cost=Dict("input"=>1.2, "output"=>1.2, "cacheRead"=>0, "cacheWrite"=>0),
            contextWindow=131072,
            maxTokens=16384,
            headers=nothing
        ),
        "thedrummer/rocinante-12b" => Model(
            id="thedrummer/rocinante-12b",
            name="TheDrummer: Rocinante 12B",
            api="openai-completions",
            provider="openrouter",
            baseUrl="https://openrouter.ai/api/v1",
            reasoning=false,
            input=["text"],
            cost=Dict("input"=>0.16999999999999998, "output"=>0.43, "cacheRead"=>0, "cacheWrite"=>0),
            contextWindow=32768,
            maxTokens=4096,
            headers=nothing
        ),
        "meta-llama/llama-3.2-3b-instruct" => Model(
            id="meta-llama/llama-3.2-3b-instruct",
            name="Meta: Llama 3.2 3B Instruct",
            api="openai-completions",
            provider="openrouter",
            baseUrl="https://openrouter.ai/api/v1",
            reasoning=false,
            input=["text"],
            cost=Dict("input"=>0.02, "output"=>0.02, "cacheRead"=>0, "cacheWrite"=>0),
            contextWindow=131072,
            maxTokens=16384,
            headers=nothing
        ),
        "qwen/qwen-2.5-72b-instruct" => Model(
            id="qwen/qwen-2.5-72b-instruct",
            name="Qwen2.5 72B Instruct",
            api="openai-completions",
            provider="openrouter",
            baseUrl="https://openrouter.ai/api/v1",
            reasoning=false,
            input=["text"],
            cost=Dict("input"=>0.07, "output"=>0.26, "cacheRead"=>0, "cacheWrite"=>0),
            contextWindow=32768,
            maxTokens=32768,
            headers=nothing
        ),
        "mistralai/pixtral-12b" => Model(
            id="mistralai/pixtral-12b",
            name="Mistral: Pixtral 12B",
            api="openai-completions",
            provider="openrouter",
            baseUrl="https://openrouter.ai/api/v1",
            reasoning=false,
            input=["text", "image"],
            cost=Dict("input"=>0.09999999999999999, "output"=>0.09999999999999999, "cacheRead"=>0, "cacheWrite"=>0),
            contextWindow=32768,
            maxTokens=4096,
            headers=nothing
        ),
        "cohere/command-r-plus-08-2024" => Model(
            id="cohere/command-r-plus-08-2024",
            name="Cohere: Command R+ (08-2024)",
            api="openai-completions",
            provider="openrouter",
            baseUrl="https://openrouter.ai/api/v1",
            reasoning=false,
            input=["text"],
            cost=Dict("input"=>2.5, "output"=>10, "cacheRead"=>0, "cacheWrite"=>0),
            contextWindow=128000,
            maxTokens=4000,
            headers=nothing
        ),
        "cohere/command-r-08-2024" => Model(
            id="cohere/command-r-08-2024",
            name="Cohere: Command R (08-2024)",
            api="openai-completions",
            provider="openrouter",
            baseUrl="https://openrouter.ai/api/v1",
            reasoning=false,
            input=["text"],
            cost=Dict("input"=>0.15, "output"=>0.6, "cacheRead"=>0, "cacheWrite"=>0),
            contextWindow=128000,
            maxTokens=4000,
            headers=nothing
        ),
        "sao10k/l3.1-euryale-70b" => Model(
            id="sao10k/l3.1-euryale-70b",
            name="Sao10K: Llama 3.1 Euryale 70B v2.2",
            api="openai-completions",
            provider="openrouter",
            baseUrl="https://openrouter.ai/api/v1",
            reasoning=false,
            input=["text"],
            cost=Dict("input"=>0.65, "output"=>0.75, "cacheRead"=>0, "cacheWrite"=>0),
            contextWindow=32768,
            maxTokens=4096,
            headers=nothing
        ),
        "microsoft/phi-3.5-mini-128k-instruct" => Model(
            id="microsoft/phi-3.5-mini-128k-instruct",
            name="Microsoft: Phi-3.5 Mini 128K Instruct",
            api="openai-completions",
            provider="openrouter",
            baseUrl="https://openrouter.ai/api/v1",
            reasoning=false,
            input=["text"],
            cost=Dict("input"=>0.09999999999999999, "output"=>0.09999999999999999, "cacheRead"=>0, "cacheWrite"=>0),
            contextWindow=128000,
            maxTokens=4096,
            headers=nothing
        ),
        "openai/gpt-4o-2024-08-06" => Model(
            id="openai/gpt-4o-2024-08-06",
            name="OpenAI: GPT-4o (2024-08-06)",
            api="openai-completions",
            provider="openrouter",
            baseUrl="https://openrouter.ai/api/v1",
            reasoning=false,
            input=["text", "image"],
            cost=Dict("input"=>2.5, "output"=>10, "cacheRead"=>1.25, "cacheWrite"=>0),
            contextWindow=128000,
            maxTokens=16384,
            headers=nothing
        ),
        "meta-llama/llama-3.1-70b-instruct" => Model(
            id="meta-llama/llama-3.1-70b-instruct",
            name="Meta: Llama 3.1 70B Instruct",
            api="openai-completions",
            provider="openrouter",
            baseUrl="https://openrouter.ai/api/v1",
            reasoning=false,
            input=["text"],
            cost=Dict("input"=>0.39999999999999997, "output"=>0.39999999999999997, "cacheRead"=>0, "cacheWrite"=>0),
            contextWindow=131072,
            maxTokens=4096,
            headers=nothing
        ),
        "meta-llama/llama-3.1-8b-instruct" => Model(
            id="meta-llama/llama-3.1-8b-instruct",
            name="Meta: Llama 3.1 8B Instruct",
            api="openai-completions",
            provider="openrouter",
            baseUrl="https://openrouter.ai/api/v1",
            reasoning=false,
            input=["text"],
            cost=Dict("input"=>0.02, "output"=>0.03, "cacheRead"=>0, "cacheWrite"=>0),
            contextWindow=131072,
            maxTokens=16384,
            headers=nothing
        ),
        "meta-llama/llama-3.1-405b-instruct" => Model(
            id="meta-llama/llama-3.1-405b-instruct",
            name="Meta: Llama 3.1 405B Instruct",
            api="openai-completions",
            provider="openrouter",
            baseUrl="https://openrouter.ai/api/v1",
            reasoning=false,
            input=["text"],
            cost=Dict("input"=>3.5, "output"=>3.5, "cacheRead"=>0, "cacheWrite"=>0),
            contextWindow=130815,
            maxTokens=4096,
            headers=nothing
        ),
        "mistralai/mistral-nemo" => Model(
            id="mistralai/mistral-nemo",
            name="Mistral: Mistral Nemo",
            api="openai-completions",
            provider="openrouter",
            baseUrl="https://openrouter.ai/api/v1",
            reasoning=false,
            input=["text"],
            cost=Dict("input"=>0.02, "output"=>0.04, "cacheRead"=>0, "cacheWrite"=>0),
            contextWindow=131072,
            maxTokens=16384,
            headers=nothing
        ),
        "openai/gpt-4o-mini" => Model(
            id="openai/gpt-4o-mini",
            name="OpenAI: GPT-4o-mini",
            api="openai-completions",
            provider="openrouter",
            baseUrl="https://openrouter.ai/api/v1",
            reasoning=false,
            input=["text", "image"],
            cost=Dict("input"=>0.15, "output"=>0.6, "cacheRead"=>0.075, "cacheWrite"=>0),
            contextWindow=128000,
            maxTokens=16384,
            headers=nothing
        ),
        "openai/gpt-4o-mini-2024-07-18" => Model(
            id="openai/gpt-4o-mini-2024-07-18",
            name="OpenAI: GPT-4o-mini (2024-07-18)",
            api="openai-completions",
            provider="openrouter",
            baseUrl="https://openrouter.ai/api/v1",
            reasoning=false,
            input=["text", "image"],
            cost=Dict("input"=>0.15, "output"=>0.6, "cacheRead"=>0.075, "cacheWrite"=>0),
            contextWindow=128000,
            maxTokens=16384,
            headers=nothing
        ),
        "sao10k/l3-euryale-70b" => Model(
            id="sao10k/l3-euryale-70b",
            name="Sao10k: Llama 3 Euryale 70B v2.1",
            api="openai-completions",
            provider="openrouter",
            baseUrl="https://openrouter.ai/api/v1",
            reasoning=false,
            input=["text"],
            cost=Dict("input"=>1.48, "output"=>1.48, "cacheRead"=>0, "cacheWrite"=>0),
            contextWindow=8192,
            maxTokens=8192,
            headers=nothing
        ),
        "mistralai/mistral-7b-instruct:free" => Model(
            id="mistralai/mistral-7b-instruct:free",
            name="Mistral: Mistral 7B Instruct (free)",
            api="openai-completions",
            provider="openrouter",
            baseUrl="https://openrouter.ai/api/v1",
            reasoning=false,
            input=["text"],
            cost=Dict("input"=>0, "output"=>0, "cacheRead"=>0, "cacheWrite"=>0),
            contextWindow=32768,
            maxTokens=16384,
            headers=nothing
        ),
        "mistralai/mistral-7b-instruct" => Model(
            id="mistralai/mistral-7b-instruct",
            name="Mistral: Mistral 7B Instruct",
            api="openai-completions",
            provider="openrouter",
            baseUrl="https://openrouter.ai/api/v1",
            reasoning=false,
            input=["text"],
            cost=Dict("input"=>0.028, "output"=>0.054, "cacheRead"=>0, "cacheWrite"=>0),
            contextWindow=32768,
            maxTokens=16384,
            headers=nothing
        ),
        "microsoft/phi-3-mini-128k-instruct" => Model(
            id="microsoft/phi-3-mini-128k-instruct",
            name="Microsoft: Phi-3 Mini 128K Instruct",
            api="openai-completions",
            provider="openrouter",
            baseUrl="https://openrouter.ai/api/v1",
            reasoning=false,
            input=["text"],
            cost=Dict("input"=>0.09999999999999999, "output"=>0.09999999999999999, "cacheRead"=>0, "cacheWrite"=>0),
            contextWindow=128000,
            maxTokens=4096,
            headers=nothing
        ),
        "microsoft/phi-3-medium-128k-instruct" => Model(
            id="microsoft/phi-3-medium-128k-instruct",
            name="Microsoft: Phi-3 Medium 128K Instruct",
            api="openai-completions",
            provider="openrouter",
            baseUrl="https://openrouter.ai/api/v1",
            reasoning=false,
            input=["text"],
            cost=Dict("input"=>1, "output"=>1, "cacheRead"=>0, "cacheWrite"=>0),
            contextWindow=128000,
            maxTokens=4096,
            headers=nothing
        ),
        "openai/gpt-4o-2024-05-13" => Model(
            id="openai/gpt-4o-2024-05-13",
            name="OpenAI: GPT-4o (2024-05-13)",
            api="openai-completions",
            provider="openrouter",
            baseUrl="https://openrouter.ai/api/v1",
            reasoning=false,
            input=["text", "image"],
            cost=Dict("input"=>5, "output"=>15, "cacheRead"=>0, "cacheWrite"=>0),
            contextWindow=128000,
            maxTokens=4096,
            headers=nothing
        ),
        "openai/gpt-4o" => Model(
            id="openai/gpt-4o",
            name="OpenAI: GPT-4o",
            api="openai-completions",
            provider="openrouter",
            baseUrl="https://openrouter.ai/api/v1",
            reasoning=false,
            input=["text", "image"],
            cost=Dict("input"=>2.5, "output"=>10, "cacheRead"=>1.25, "cacheWrite"=>0),
            contextWindow=128000,
            maxTokens=16384,
            headers=nothing
        ),
        "openai/gpt-4o:extended" => Model(
            id="openai/gpt-4o:extended",
            name="OpenAI: GPT-4o (extended)",
            api="openai-completions",
            provider="openrouter",
            baseUrl="https://openrouter.ai/api/v1",
            reasoning=false,
            input=["text", "image"],
            cost=Dict("input"=>6, "output"=>18, "cacheRead"=>0, "cacheWrite"=>0),
            contextWindow=128000,
            maxTokens=64000,
            headers=nothing
        ),
        "meta-llama/llama-3-70b-instruct" => Model(
            id="meta-llama/llama-3-70b-instruct",
            name="Meta: Llama 3 70B Instruct",
            api="openai-completions",
            provider="openrouter",
            baseUrl="https://openrouter.ai/api/v1",
            reasoning=false,
            input=["text"],
            cost=Dict("input"=>0.3, "output"=>0.39999999999999997, "cacheRead"=>0, "cacheWrite"=>0),
            contextWindow=8192,
            maxTokens=16384,
            headers=nothing
        ),
        "meta-llama/llama-3-8b-instruct" => Model(
            id="meta-llama/llama-3-8b-instruct",
            name="Meta: Llama 3 8B Instruct",
            api="openai-completions",
            provider="openrouter",
            baseUrl="https://openrouter.ai/api/v1",
            reasoning=false,
            input=["text"],
            cost=Dict("input"=>0.03, "output"=>0.06, "cacheRead"=>0, "cacheWrite"=>0),
            contextWindow=8192,
            maxTokens=16384,
            headers=nothing
        ),
        "mistralai/mixtral-8x22b-instruct" => Model(
            id="mistralai/mixtral-8x22b-instruct",
            name="Mistral: Mixtral 8x22B Instruct",
            api="openai-completions",
            provider="openrouter",
            baseUrl="https://openrouter.ai/api/v1",
            reasoning=false,
            input=["text"],
            cost=Dict("input"=>2, "output"=>6, "cacheRead"=>0, "cacheWrite"=>0),
            contextWindow=65536,
            maxTokens=4096,
            headers=nothing
        ),
        "openai/gpt-4-turbo" => Model(
            id="openai/gpt-4-turbo",
            name="OpenAI: GPT-4 Turbo",
            api="openai-completions",
            provider="openrouter",
            baseUrl="https://openrouter.ai/api/v1",
            reasoning=false,
            input=["text", "image"],
            cost=Dict("input"=>10, "output"=>30, "cacheRead"=>0, "cacheWrite"=>0),
            contextWindow=128000,
            maxTokens=4096,
            headers=nothing
        ),
        "anthropic/claude-3-haiku" => Model(
            id="anthropic/claude-3-haiku",
            name="Anthropic: Claude 3 Haiku",
            api="openai-completions",
            provider="openrouter",
            baseUrl="https://openrouter.ai/api/v1",
            reasoning=false,
            input=["text", "image"],
            cost=Dict("input"=>0.25, "output"=>1.25, "cacheRead"=>0.03, "cacheWrite"=>0.3),
            contextWindow=200000,
            maxTokens=4096,
            headers=nothing
        ),
        "anthropic/claude-3-opus" => Model(
            id="anthropic/claude-3-opus",
            name="Anthropic: Claude 3 Opus",
            api="openai-completions",
            provider="openrouter",
            baseUrl="https://openrouter.ai/api/v1",
            reasoning=false,
            input=["text", "image"],
            cost=Dict("input"=>15, "output"=>75, "cacheRead"=>1.5, "cacheWrite"=>18.75),
            contextWindow=200000,
            maxTokens=4096,
            headers=nothing
        ),
        "mistralai/mistral-large" => Model(
            id="mistralai/mistral-large",
            name="Mistral Large",
            api="openai-completions",
            provider="openrouter",
            baseUrl="https://openrouter.ai/api/v1",
            reasoning=false,
            input=["text"],
            cost=Dict("input"=>2, "output"=>6, "cacheRead"=>0, "cacheWrite"=>0),
            contextWindow=128000,
            maxTokens=4096,
            headers=nothing
        ),
        "openai/gpt-3.5-turbo-0613" => Model(
            id="openai/gpt-3.5-turbo-0613",
            name="OpenAI: GPT-3.5 Turbo (older v0613)",
            api="openai-completions",
            provider="openrouter",
            baseUrl="https://openrouter.ai/api/v1",
            reasoning=false,
            input=["text"],
            cost=Dict("input"=>1, "output"=>2, "cacheRead"=>0, "cacheWrite"=>0),
            contextWindow=4095,
            maxTokens=4096,
            headers=nothing
        ),
        "openai/gpt-4-turbo-preview" => Model(
            id="openai/gpt-4-turbo-preview",
            name="OpenAI: GPT-4 Turbo Preview",
            api="openai-completions",
            provider="openrouter",
            baseUrl="https://openrouter.ai/api/v1",
            reasoning=false,
            input=["text"],
            cost=Dict("input"=>10, "output"=>30, "cacheRead"=>0, "cacheWrite"=>0),
            contextWindow=128000,
            maxTokens=4096,
            headers=nothing
        ),
        "mistralai/mistral-small" => Model(
            id="mistralai/mistral-small",
            name="Mistral Small",
            api="openai-completions",
            provider="openrouter",
            baseUrl="https://openrouter.ai/api/v1",
            reasoning=false,
            input=["text"],
            cost=Dict("input"=>0.19999999999999998, "output"=>0.6, "cacheRead"=>0, "cacheWrite"=>0),
            contextWindow=32768,
            maxTokens=4096,
            headers=nothing
        ),
        "mistralai/mistral-tiny" => Model(
            id="mistralai/mistral-tiny",
            name="Mistral Tiny",
            api="openai-completions",
            provider="openrouter",
            baseUrl="https://openrouter.ai/api/v1",
            reasoning=false,
            input=["text"],
            cost=Dict("input"=>0.25, "output"=>0.25, "cacheRead"=>0, "cacheWrite"=>0),
            contextWindow=32768,
            maxTokens=4096,
            headers=nothing
        ),
        "mistralai/mixtral-8x7b-instruct" => Model(
            id="mistralai/mixtral-8x7b-instruct",
            name="Mistral: Mixtral 8x7B Instruct",
            api="openai-completions",
            provider="openrouter",
            baseUrl="https://openrouter.ai/api/v1",
            reasoning=false,
            input=["text"],
            cost=Dict("input"=>0.54, "output"=>0.54, "cacheRead"=>0, "cacheWrite"=>0),
            contextWindow=32768,
            maxTokens=16384,
            headers=nothing
        ),
        "openai/gpt-4-1106-preview" => Model(
            id="openai/gpt-4-1106-preview",
            name="OpenAI: GPT-4 Turbo (older v1106)",
            api="openai-completions",
            provider="openrouter",
            baseUrl="https://openrouter.ai/api/v1",
            reasoning=false,
            input=["text"],
            cost=Dict("input"=>10, "output"=>30, "cacheRead"=>0, "cacheWrite"=>0),
            contextWindow=128000,
            maxTokens=4096,
            headers=nothing
        ),
        "openai/gpt-3.5-turbo-16k" => Model(
            id="openai/gpt-3.5-turbo-16k",
            name="OpenAI: GPT-3.5 Turbo 16k",
            api="openai-completions",
            provider="openrouter",
            baseUrl="https://openrouter.ai/api/v1",
            reasoning=false,
            input=["text"],
            cost=Dict("input"=>3, "output"=>4, "cacheRead"=>0, "cacheWrite"=>0),
            contextWindow=16385,
            maxTokens=4096,
            headers=nothing
        ),
        "openai/gpt-3.5-turbo" => Model(
            id="openai/gpt-3.5-turbo",
            name="OpenAI: GPT-3.5 Turbo",
            api="openai-completions",
            provider="openrouter",
            baseUrl="https://openrouter.ai/api/v1",
            reasoning=false,
            input=["text"],
            cost=Dict("input"=>0.5, "output"=>1.5, "cacheRead"=>0, "cacheWrite"=>0),
            contextWindow=16385,
            maxTokens=4096,
            headers=nothing
        ),
        "openai/gpt-4-0314" => Model(
            id="openai/gpt-4-0314",
            name="OpenAI: GPT-4 (older v0314)",
            api="openai-completions",
            provider="openrouter",
            baseUrl="https://openrouter.ai/api/v1",
            reasoning=false,
            input=["text"],
            cost=Dict("input"=>30, "output"=>60, "cacheRead"=>0, "cacheWrite"=>0),
            contextWindow=8191,
            maxTokens=4096,
            headers=nothing
        ),
        "openai/gpt-4" => Model(
            id="openai/gpt-4",
            name="OpenAI: GPT-4",
            api="openai-completions",
            provider="openrouter",
            baseUrl="https://openrouter.ai/api/v1",
            reasoning=false,
            input=["text"],
            cost=Dict("input"=>30, "output"=>60, "cacheRead"=>0, "cacheWrite"=>0),
            contextWindow=8191,
            maxTokens=4096,
            headers=nothing
        ),
        "openrouter/auto" => Model(
            id="openrouter/auto",
            name="OpenRouter: Auto Router",
            api="openai-completions",
            provider="openrouter",
            baseUrl="https://openrouter.ai/api/v1",
            reasoning=true,
            input=["text", "image"],
            cost=Dict("input"=>0, "output"=>0, "cacheRead"=>0, "cacheWrite"=>0),
            contextWindow=2000000,
            maxTokens=30000,
            headers=nothing
        ),
    )

end

# Initialize on module load
_init_model_registry!()
